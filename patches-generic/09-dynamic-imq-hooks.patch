--- backfire-orig/target/linux/generic-2.6/patches-2.6.30/150-netfilter_imq.patch	2010-07-30 16:54:01.000000000 -0400
+++ backfire/target/linux/generic-2.6/patches-2.6.30/150-netfilter_imq.patch	2010-07-30 16:58:24.000000000 -0400
@@ -1,1260 +1,1509 @@
---- /dev/null
-+++ b/drivers/net/imq.c
-@@ -0,0 +1,571 @@
-+/*
-+ *             Pseudo-driver for the intermediate queue device.
-+ *
-+ *             This program is free software; you can redistribute it and/or
-+ *             modify it under the terms of the GNU General Public License
-+ *             as published by the Free Software Foundation; either version
-+ *             2 of the License, or (at your option) any later version.
-+ *
-+ * Authors:    Patrick McHardy, <kaber@trash.net>
-+ *
-+ *            The first version was written by Martin Devera, <devik@cdi.cz>
-+ *
-+ * Credits:    Jan Rafaj <imq2t@cedric.vabo.cz>
-+ *              - Update patch to 2.4.21
-+ *             Sebastian Strollo <sstrollo@nortelnetworks.com>
-+ *              - Fix "Dead-loop on netdevice imq"-issue
-+ *             Marcel Sebek <sebek64@post.cz>
-+ *              - Update to 2.6.2-rc1
-+ *
-+ *	       After some time of inactivity there is a group taking care
-+ *	       of IMQ again: http://www.linuximq.net
-+ *
-+ *
-+ *	       2004/06/30 - New version of IMQ patch to kernels <=2.6.7
-+ *             including the following changes:
-+ *
-+ *	       - Correction of ipv6 support "+"s issue (Hasso Tepper)
-+ *	       - Correction of imq_init_devs() issue that resulted in
-+ *	       kernel OOPS unloading IMQ as module (Norbert Buchmuller)
-+ *	       - Addition of functionality to choose number of IMQ devices
-+ *	       during kernel config (Andre Correa)
-+ *	       - Addition of functionality to choose how IMQ hooks on
-+ *	       PRE and POSTROUTING (after or before NAT) (Andre Correa)
-+ *	       - Cosmetic corrections (Norbert Buchmuller) (Andre Correa)
-+ *
-+ *
-+ *             2005/12/16 - IMQ versions between 2.6.7 and 2.6.13 were
-+ *             released with almost no problems. 2.6.14-x was released
-+ *             with some important changes: nfcache was removed; After
-+ *             some weeks of trouble we figured out that some IMQ fields
-+ *             in skb were missing in skbuff.c - skb_clone and copy_skb_header.
-+ *             These functions are correctly patched by this new patch version.
-+ *
-+ *             Thanks for all who helped to figure out all the problems with
-+ *             2.6.14.x: Patrick McHardy, Rune Kock, VeNoMouS, Max CtRiX,
-+ *             Kevin Shanahan, Richard Lucassen, Valery Dachev (hopefully
-+ *             I didn't forget anybody). I apologize again for my lack of time.
-+ *
-+ *
-+ *             2008/06/17 - 2.6.25 - Changed imq.c to use qdisc_run() instead
-+ *             of qdisc_restart() and moved qdisc_run() to tasklet to avoid
-+ *             recursive locking. New initialization routines to fix 'rmmod' not
-+ *             working anymore. Used code from ifb.c. (Jussi Kivilinna)
-+ *
-+ *             2008/08/06 - 2.6.26 - (JK)
-+ *              - Replaced tasklet with 'netif_schedule()'.
-+ *              - Cleaned up and added comments for imq_nf_queue().
-+ *
-+ *             2009/04/12
-+ *              - Add skb_save_cb/skb_restore_cb helper functions for backuping
-+ *                control buffer. This is needed because qdisc-layer on kernels
-+ *                2.6.27 and newer overwrite control buffer. (Jussi Kivilinna)
-+ *              - Add better locking for IMQ device. Hopefully this will solve
-+ *                SMP issues. (Jussi Kivilinna)
-+ *              - Port to 2.6.27
-+ *              - Port to 2.6.28
-+ *              - Port to 2.6.29 + fix rmmod not working
-+ *
-+ *             2009/04/20 - (Jussi Kivilinna)
-+ *              - Use netdevice feature flags to avoid extra packet handling
-+ *                by core networking layer and possibly increase performance.
-+ *
-+ *	       Also, many thanks to pablo Sebastian Greco for making the initial
-+ *	       patch and to those who helped the testing.
-+ *
-+ *             More info at: http://www.linuximq.net/ (Andre Correa)
-+ */
+--- a/drivers/net/Kconfig
++++ b/drivers/net/Kconfig
+@@ -119,6 +119,129 @@ config EQUALIZER
+ 	  To compile this driver as a module, choose M here: the module
+ 	  will be called eql.  If unsure, say N.
+ 
++config IMQ
++	tristate "IMQ (intermediate queueing device) support"
++	depends on NETDEVICES && NETFILTER
++	---help---
++	  The IMQ device(s) is used as placeholder for QoS queueing
++	  disciplines. Every packet entering/leaving the IP stack can be
++	  directed through the IMQ device where it's enqueued/dequeued to the
++	  attached qdisc. This allows you to treat network devices as classes
++	  and distribute bandwidth among them. Iptables is used to specify
++	  through which IMQ device, if any, packets travel.
 +
-+#include <linux/module.h>
-+#include <linux/kernel.h>
-+#include <linux/moduleparam.h>
-+#include <linux/list.h>
-+#include <linux/skbuff.h>
-+#include <linux/netdevice.h>
-+#include <linux/etherdevice.h>
-+#include <linux/rtnetlink.h>
-+#include <linux/if_arp.h>
-+#include <linux/netfilter.h>
-+#include <linux/netfilter_ipv4.h>
-+#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
-+	#include <linux/netfilter_ipv6.h>
-+#endif
-+#include <linux/imq.h>
-+#include <net/pkt_sched.h>
-+#include <net/netfilter/nf_queue.h>
++	  More information at: http://www.linuximq.net/
 +
-+static nf_hookfn imq_nf_hook;
++	  To compile this driver as a module, choose M here: the module
++	  will be called imq.  If unsure, say N.
 +
-+static struct nf_hook_ops imq_ingress_ipv4 = {
-+	.hook		= imq_nf_hook,
-+	.owner		= THIS_MODULE,
-+	.pf		= PF_INET,
-+	.hooknum	= NF_INET_PRE_ROUTING,
-+#if defined(CONFIG_IMQ_BEHAVIOR_BA) || defined(CONFIG_IMQ_BEHAVIOR_BB)
-+	.priority	= NF_IP_PRI_MANGLE + 1
-+#else
-+	.priority	= NF_IP_PRI_NAT_DST + 1
-+#endif
-+};
++choice
++	prompt "IMQ behavior (PRE/POSTROUTING)"
++	depends on IMQ
++	default IMQ_BEHAVIOR_AB
++	help
 +
-+static struct nf_hook_ops imq_egress_ipv4 = {
-+	.hook		= imq_nf_hook,
-+	.owner		= THIS_MODULE,
-+	.pf		= PF_INET,
-+	.hooknum	= NF_INET_POST_ROUTING,
-+#if defined(CONFIG_IMQ_BEHAVIOR_AA) || defined(CONFIG_IMQ_BEHAVIOR_BA)
-+	.priority	= NF_IP_PRI_LAST
-+#else
-+	.priority	= NF_IP_PRI_NAT_SRC - 1
-+#endif
-+};
++		This settings defines how IMQ behaves in respect to its
++		hooking in PREROUTING and POSTROUTING.
 +
-+#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
-+static struct nf_hook_ops imq_ingress_ipv6 = {
-+	.hook		= imq_nf_hook,
-+	.owner		= THIS_MODULE,
-+	.pf		= PF_INET6,
-+	.hooknum	= NF_INET_PRE_ROUTING,
-+#if defined(CONFIG_IMQ_BEHAVIOR_BA) || defined(CONFIG_IMQ_BEHAVIOR_BB)
-+	.priority	= NF_IP6_PRI_MANGLE + 1
-+#else
-+	.priority	= NF_IP6_PRI_NAT_DST + 1
-+#endif
-+};
++		IMQ can work in any of the following ways:
 +
-+static struct nf_hook_ops imq_egress_ipv6 = {
-+	.hook		= imq_nf_hook,
-+	.owner		= THIS_MODULE,
-+	.pf		= PF_INET6,
-+	.hooknum	= NF_INET_POST_ROUTING,
-+#if defined(CONFIG_IMQ_BEHAVIOR_AA) || defined(CONFIG_IMQ_BEHAVIOR_BA)
-+	.priority	= NF_IP6_PRI_LAST
-+#else
-+	.priority	= NF_IP6_PRI_NAT_SRC - 1
-+#endif
-+};
-+#endif
++		    PREROUTING   |      POSTROUTING
++		-----------------|-------------------
++		#1  After NAT    |      After NAT
++		#2  After NAT    |      Before NAT
++		#3  Before NAT   |      After NAT
++		#4  Before NAT   |      Before NAT
 +
-+#if defined(CONFIG_IMQ_NUM_DEVS)
-+static unsigned int numdevs = CONFIG_IMQ_NUM_DEVS;
-+#else
-+static unsigned int numdevs = IMQ_MAX_DEVS;
-+#endif
++		The default behavior is to hook before NAT on PREROUTING
++		and after NAT on POSTROUTING (#3).
 +
-+static DEFINE_SPINLOCK(imq_nf_queue_lock);
++		This settings are specially usefull when trying to use IMQ
++		to shape NATed clients.
 +
-+static struct net_device *imq_devs_cache[IMQ_MAX_DEVS];
++		More information can be found at: www.linuximq.net
 +
++		If not sure leave the default settings alone.
 +
-+static struct net_device_stats *imq_get_stats(struct net_device *dev)
-+{
-+	return &dev->stats;
-+}
++config IMQ_BEHAVIOR_AA
++	bool "IMQ AA"
++	help
++		This settings defines how IMQ behaves in respect to its
++		hooking in PREROUTING and POSTROUTING.
 +
-+/* called for packets kfree'd in qdiscs at places other than enqueue */
-+static void imq_skb_destructor(struct sk_buff *skb)
-+{
-+	struct nf_queue_entry *entry = skb->nf_queue_entry;
++		Choosing this option will make IMQ hook like this:
 +
-+	if (entry) {
-+		nf_queue_entry_release_refs(entry);
-+		kfree(entry);
-+	}
++		PREROUTING:   After NAT
++		POSTROUTING:  After NAT
 +
-+	skb_restore_cb(skb); /* kfree backup */
-+}
++		More information can be found at: www.linuximq.net
 +
-+static void imq_nf_reinject(struct nf_queue_entry *entry, unsigned int verdict)
-+{
-+	int status;
++		If not sure leave the default settings alone.
 +
-+	if (!entry->next_outfn) {
-+		spin_lock_bh(&imq_nf_queue_lock);
-+		nf_reinject(entry, verdict);
-+		spin_unlock_bh(&imq_nf_queue_lock);
-+		return;
-+	}
++config IMQ_BEHAVIOR_AB
++	bool "IMQ AB"
++	help
++		This settings defines how IMQ behaves in respect to its
++		hooking in PREROUTING and POSTROUTING.
 +
-+	rcu_read_lock();
-+	local_bh_disable();
-+	status = entry->next_outfn(entry, entry->next_queuenum);
-+	local_bh_enable();
-+	if (status < 0) {
-+		nf_queue_entry_release_refs(entry);
-+		kfree_skb(entry->skb);
-+		kfree(entry);
-+	}
++		Choosing this option will make IMQ hook like this:
 +
-+	rcu_read_unlock();
-+}
++		PREROUTING:   After NAT
++		POSTROUTING:  Before NAT
 +
-+static int imq_dev_xmit(struct sk_buff *skb, struct net_device *dev)
-+{
-+	dev->stats.tx_bytes += skb->len;
-+	dev->stats.tx_packets++;
++		More information can be found at: www.linuximq.net
 +
-+	skb->imq_flags = 0;
-+	skb->destructor = NULL;
++		If not sure leave the default settings alone.
 +
-+	skb_restore_cb(skb); /* restore skb->cb */
++config IMQ_BEHAVIOR_BA
++	bool "IMQ BA"
++	help
++		This settings defines how IMQ behaves in respect to its
++		hooking in PREROUTING and POSTROUTING.
 +
-+	dev->trans_start = jiffies;
-+	imq_nf_reinject(skb->nf_queue_entry, NF_ACCEPT);
-+	return 0;
-+}
++		Choosing this option will make IMQ hook like this:
 +
-+static int imq_nf_queue(struct nf_queue_entry *entry, unsigned queue_num)
-+{
-+	struct net_device *dev;
-+	struct sk_buff *skb_orig, *skb, *skb_shared;
-+	struct Qdisc *q;
-+	struct netdev_queue *txq;
-+	int users, index;
-+	int retval = -EINVAL;
++		PREROUTING:   Before NAT
++		POSTROUTING:  After NAT
 +
-+	index = entry->skb->imq_flags & IMQ_F_IFMASK;
-+	if (unlikely(index > numdevs - 1)) {
-+		if (net_ratelimit())
-+			printk(KERN_WARNING
-+			       "IMQ: invalid device specified, highest is %u\n",
-+			       numdevs - 1);
-+		retval = -EINVAL;
-+		goto out;
-+	}
++		More information can be found at: www.linuximq.net
 +
-+	/* check for imq device by index from cache */
-+	dev = imq_devs_cache[index];
-+	if (unlikely(!dev)) {
-+		char buf[8];
++		If not sure leave the default settings alone.
 +
-+		/* get device by name and cache result */
-+		snprintf(buf, sizeof(buf), "imq%d", index);
-+		dev = dev_get_by_name(&init_net, buf);
-+		if (!dev) {
-+			/* not found ?!*/
-+			BUG();
-+			retval = -ENODEV;
-+			goto out;
-+		}
-+
-+		imq_devs_cache[index] = dev;
-+		dev_put(dev);
-+	}
-+
-+	if (unlikely(!(dev->flags & IFF_UP))) {
-+		entry->skb->imq_flags = 0;
-+		imq_nf_reinject(entry, NF_ACCEPT);
-+		retval = 0;
-+		goto out;
-+	}
-+	dev->last_rx = jiffies;
++config IMQ_BEHAVIOR_BB
++	bool "IMQ BB"
++	help
++		This settings defines how IMQ behaves in respect to its
++		hooking in PREROUTING and POSTROUTING.
 +
-+	skb = entry->skb;
-+	skb_orig = NULL;
++		Choosing this option will make IMQ hook like this:
 +
-+	/* skb has owner? => make clone */
-+	if (unlikely(skb->destructor)) {
-+		skb_orig = skb;
-+		skb = skb_clone(skb, GFP_ATOMIC);
-+		if (!skb) {
-+			retval = -ENOMEM;
-+			goto out;
-+		}
-+		entry->skb = skb;
-+	}
++		PREROUTING:   Before NAT
++		POSTROUTING:  Before NAT
 +
-+	skb->nf_queue_entry = entry;
++		More information can be found at: www.linuximq.net
 +
-+	dev->stats.rx_bytes += skb->len;
-+	dev->stats.rx_packets++;
++		If not sure leave the default settings alone.
 +
-+	txq = dev_pick_tx(dev, skb);
++endchoice
 +
-+	q = rcu_dereference(txq->qdisc);
-+	if (unlikely(!q->enqueue))
-+		goto packet_not_eaten_by_imq_dev;
++config IMQ_NUM_DEVS
 +
-+	spin_lock_bh(qdisc_lock(q));
++	int "Number of IMQ devices"
++	range 2 16
++	depends on IMQ
++	default "16"
++	help
 +
-+	users = atomic_read(&skb->users);
++		This settings defines how many IMQ devices will be
++		created.
 +
-+	skb_shared = skb_get(skb); /* increase reference count by one */
-+	skb_save_cb(skb_shared); /* backup skb->cb, as qdisc layer will
-+					overwrite it */
-+	qdisc_enqueue_root(skb_shared, q); /* might kfree_skb */
++		The default value is 16.
 +
-+	if (likely(atomic_read(&skb_shared->users) == users + 1)) {
-+		kfree_skb(skb_shared); /* decrease reference count by one */
++		More information can be found at: www.linuximq.net
 +
-+		skb->destructor = &imq_skb_destructor;
++		If not sure leave the default settings alone.
 +
-+		/* cloned? */
-+		if (skb_orig)
-+			kfree_skb(skb_orig); /* free original */
+ config TUN
+ 	tristate "Universal TUN/TAP device driver support"
+ 	select CRC32
+--- a/drivers/net/Makefile
++++ b/drivers/net/Makefile
+@@ -152,6 +152,7 @@ obj-$(CONFIG_SLHC) += slhc.o
+ obj-$(CONFIG_XEN_NETDEV_FRONTEND) += xen-netfront.o
+ 
+ obj-$(CONFIG_DUMMY) += dummy.o
++obj-$(CONFIG_IMQ) += imq.o
+ obj-$(CONFIG_IFB) += ifb.o
+ obj-$(CONFIG_MACVLAN) += macvlan.o
+ obj-$(CONFIG_DE600) += de600.o
+--- /dev/null
++++ b/include/linux/imq.h
+@@ -0,0 +1,13 @@
++#ifndef _IMQ_H
++#define _IMQ_H
 +
-+		spin_unlock_bh(qdisc_lock(q));
++/* IFMASK (16 device indexes, 0 to 15) and flag(s) fit in 5 bits */
++#define IMQ_F_BITS	5
 +
-+		/* schedule qdisc dequeue */
-+		__netif_schedule(q);
++#define IMQ_F_IFMASK	0x0f
++#define IMQ_F_ENQUEUE	0x10
 +
-+		retval = 0;
-+		goto out;
-+	} else {
-+		skb_restore_cb(skb_shared); /* restore skb->cb */
-+		/* qdisc dropped packet and decreased skb reference count of
-+		 * skb, so we don't really want to and try refree as that would
-+		 * actually destroy the skb. */
-+		spin_unlock_bh(qdisc_lock(q));
-+		goto packet_not_eaten_by_imq_dev;
-+	}
++#define IMQ_MAX_DEVS	(IMQ_F_IFMASK + 1)
 +
-+packet_not_eaten_by_imq_dev:
-+	/* cloned? restore original */
-+	if (skb_orig) {
-+		kfree_skb(skb);
-+		entry->skb = skb_orig;
-+	}
-+	retval = -1;
-+out:
-+	return retval;
-+}
++#endif /* _IMQ_H */
 +
-+static struct nf_queue_handler nfqh = {
-+	.name  = "imq",
-+	.outfn = imq_nf_queue,
-+};
+--- /dev/null
++++ b/include/linux/netfilter_ipv4/ipt_IMQ.h
+@@ -0,0 +1,10 @@
++#ifndef _IPT_IMQ_H
++#define _IPT_IMQ_H
 +
-+static unsigned int imq_nf_hook(unsigned int hook, struct sk_buff *pskb,
-+				const struct net_device *indev,
-+				const struct net_device *outdev,
-+				int (*okfn)(struct sk_buff *))
-+{
-+	if (pskb->imq_flags & IMQ_F_ENQUEUE)
-+		return NF_QUEUE;
++/* Backwards compatibility for old userspace */
++#include <linux/netfilter/xt_IMQ.h>
 +
-+	return NF_ACCEPT;
-+}
++#define ipt_imq_info xt_imq_info
 +
-+static int imq_close(struct net_device *dev)
-+{
-+	netif_stop_queue(dev);
-+	return 0;
-+}
++#endif /* _IPT_IMQ_H */
 +
-+static int imq_open(struct net_device *dev)
-+{
-+	netif_start_queue(dev);
-+	return 0;
-+}
+--- /dev/null
++++ b/include/linux/netfilter_ipv6/ip6t_IMQ.h
+@@ -0,0 +1,10 @@
++#ifndef _IP6T_IMQ_H
++#define _IP6T_IMQ_H
 +
-+static const struct net_device_ops imq_netdev_ops = {
-+	.ndo_open		= imq_open,
-+	.ndo_stop		= imq_close,
-+	.ndo_start_xmit		= imq_dev_xmit,
-+	.ndo_get_stats		= imq_get_stats,
-+};
++/* Backwards compatibility for old userspace */
++#include <linux/netfilter/xt_IMQ.h>
 +
-+static void imq_setup(struct net_device *dev)
-+{
-+	dev->netdev_ops		= &imq_netdev_ops;
-+	dev->type               = ARPHRD_VOID;
-+	dev->mtu                = 16000;
-+	dev->tx_queue_len       = 11000;
-+	dev->flags              = IFF_NOARP;
-+	dev->features           = NETIF_F_SG | NETIF_F_FRAGLIST |
-+				  NETIF_F_GSO | NETIF_F_HW_CSUM |
-+				  NETIF_F_HIGHDMA;
-+}
++#define ip6t_imq_info xt_imq_info
 +
-+static int imq_validate(struct nlattr *tb[], struct nlattr *data[])
-+{
-+	int ret = 0;
++#endif /* _IP6T_IMQ_H */
 +
-+	if (tb[IFLA_ADDRESS]) {
-+		if (nla_len(tb[IFLA_ADDRESS]) != ETH_ALEN) {
-+			ret = -EINVAL;
-+			goto end;
-+		}
-+		if (!is_valid_ether_addr(nla_data(tb[IFLA_ADDRESS]))) {
-+			ret = -EADDRNOTAVAIL;
-+			goto end;
-+		}
-+	}
-+	return 0;
-+end:
-+	printk(KERN_WARNING "IMQ: imq_validate failed (%d)\n", ret);
-+	return ret;
-+}
+--- a/include/linux/skbuff.h
++++ b/include/linux/skbuff.h
+@@ -28,6 +28,9 @@
+ #include <linux/rcupdate.h>
+ #include <linux/dmaengine.h>
+ #include <linux/hrtimer.h>
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++#include <linux/imq.h>
++#endif
+ 
+ /* Don't change this without changing skb_csum_unnecessary! */
+ #define CHECKSUM_NONE 0
+@@ -333,6 +336,9 @@ struct sk_buff {
+ 	 * first. This is owned by whoever has the skb queued ATM.
+ 	 */
+ 	char			cb[48];
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++	void			*cb_next;
++#endif
+ 
+ 	unsigned int		len,
+ 				data_len;
+@@ -363,6 +369,9 @@ struct sk_buff {
+ 	struct nf_conntrack	*nfct;
+ 	struct sk_buff		*nfct_reasm;
+ #endif
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++	struct nf_queue_entry	*nf_queue_entry;
++#endif
+ #ifdef CONFIG_BRIDGE_NETFILTER
+ 	struct nf_bridge_info	*nf_bridge;
+ #endif
+@@ -383,6 +392,9 @@ struct sk_buff {
+ 	__u8			requeue:1;
+ #endif
+ 	/* 0/13/14 bit hole */
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++	__u8			imq_flags:IMQ_F_BITS;
++#endif
+ 
+ #ifdef CONFIG_NET_DMA
+ 	dma_cookie_t		dma_cookie;
+@@ -423,6 +435,12 @@ extern void skb_dma_unmap(struct device 
+ 			  enum dma_data_direction dir);
+ #endif
+ 
 +
-+static struct rtnl_link_ops imq_link_ops __read_mostly = {
-+	.kind		= "imq",
-+	.priv_size	= 0,
-+	.setup		= imq_setup,
-+	.validate	= imq_validate,
-+};
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++extern int skb_save_cb(struct sk_buff *skb);
++extern int skb_restore_cb(struct sk_buff *skb);
++#endif
 +
-+static int __init imq_init_hooks(void)
-+{
-+	int err;
+ extern void kfree_skb(struct sk_buff *skb);
+ extern void consume_skb(struct sk_buff *skb);
+ extern void	       __kfree_skb(struct sk_buff *skb);
+@@ -1931,6 +1949,10 @@ static inline void __nf_copy(struct sk_b
+ 	dst->nfct_reasm = src->nfct_reasm;
+ 	nf_conntrack_get_reasm(src->nfct_reasm);
+ #endif
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++	dst->imq_flags = src->imq_flags;
++	dst->nf_queue_entry = src->nf_queue_entry;
++#endif
+ #ifdef CONFIG_BRIDGE_NETFILTER
+ 	dst->nf_bridge  = src->nf_bridge;
+ 	nf_bridge_get(src->nf_bridge);
+--- a/net/core/dev.c
++++ b/net/core/dev.c
+@@ -96,6 +96,9 @@
+ #include <net/net_namespace.h>
+ #include <net/sock.h>
+ #include <linux/rtnetlink.h>
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++#include <linux/imq.h>
++#endif
+ #include <linux/proc_fs.h>
+ #include <linux/seq_file.h>
+ #include <linux/stat.h>
+@@ -1678,7 +1681,11 @@ int dev_hard_start_xmit(struct sk_buff *
+ 	int rc;
+ 
+ 	if (likely(!skb->next)) {
+-		if (!list_empty(&ptype_all))
++		if (!list_empty(&ptype_all)
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++		    && !(skb->imq_flags & IMQ_F_ENQUEUE)
++#endif
++		    )
+ 			dev_queue_xmit_nit(skb, dev);
+ 
+ 		if (netif_needs_gso(dev, skb)) {
+@@ -1749,8 +1756,7 @@ u16 skb_tx_hash(const struct net_device 
+ }
+ EXPORT_SYMBOL(skb_tx_hash);
+ 
+-static struct netdev_queue *dev_pick_tx(struct net_device *dev,
+-					struct sk_buff *skb)
++struct netdev_queue *dev_pick_tx(struct net_device *dev, struct sk_buff *skb)
+ {
+ 	const struct net_device_ops *ops = dev->netdev_ops;
+ 	u16 queue_index = 0;
+@@ -1763,6 +1769,7 @@ static struct netdev_queue *dev_pick_tx(
+ 	skb_set_queue_mapping(skb, queue_index);
+ 	return netdev_get_tx_queue(dev, queue_index);
+ }
++EXPORT_SYMBOL(dev_pick_tx);
+ 
+ /**
+  *	dev_queue_xmit - transmit a buffer
+--- a/include/linux/netdevice.h
++++ b/include/linux/netdevice.h
+@@ -1102,6 +1102,7 @@ extern int		dev_alloc_name(struct net_de
+ extern int		dev_open(struct net_device *dev);
+ extern int		dev_close(struct net_device *dev);
+ extern void		dev_disable_lro(struct net_device *dev);
++extern struct netdev_queue *dev_pick_tx(struct net_device *dev, struct sk_buff *skb);
+ extern int		dev_queue_xmit(struct sk_buff *skb);
+ extern int		register_netdevice(struct net_device *dev);
+ extern void		unregister_netdevice(struct net_device *dev);
+--- /dev/null
++++ b/include/linux/netfilter/xt_IMQ.h
+@@ -0,0 +1,9 @@
++#ifndef _XT_IMQ_H
++#define _XT_IMQ_H
 +
-+	nf_register_queue_imq_handler(&nfqh);
++struct xt_imq_info {
++	unsigned int todev;     /* target imq device */
++};
 +
-+	err = nf_register_hook(&imq_ingress_ipv4);
-+	if (err)
-+		goto err1;
-+
-+	err = nf_register_hook(&imq_egress_ipv4);
-+	if (err)
-+		goto err2;
++#endif /* _XT_IMQ_H */
 +
-+#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
-+	err = nf_register_hook(&imq_ingress_ipv6);
-+	if (err)
-+		goto err3;
-+
-+	err = nf_register_hook(&imq_egress_ipv6);
-+	if (err)
-+		goto err4;
+--- a/include/net/netfilter/nf_queue.h
++++ b/include/net/netfilter/nf_queue.h
+@@ -13,6 +13,12 @@ struct nf_queue_entry {
+ 	struct net_device	*indev;
+ 	struct net_device	*outdev;
+ 	int			(*okfn)(struct sk_buff *);
++
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++	int			(*next_outfn)(struct nf_queue_entry *entry,
++					      unsigned int queuenum);
++	unsigned int		next_queuenum;
 +#endif
+ };
+ 
+ #define nf_queue_entry_reroute(x) ((void *)x + sizeof(struct nf_queue_entry))
+@@ -30,5 +36,11 @@ extern int nf_unregister_queue_handler(u
+ 				       const struct nf_queue_handler *qh);
+ extern void nf_unregister_queue_handlers(const struct nf_queue_handler *qh);
+ extern void nf_reinject(struct nf_queue_entry *entry, unsigned int verdict);
++extern void nf_queue_entry_release_refs(struct nf_queue_entry *entry);
 +
-+	return 0;
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++extern void nf_register_queue_imq_handler(const struct nf_queue_handler *qh);
++extern void nf_unregister_queue_imq_handler(void);
++#endif
+ 
+ #endif /* _NF_QUEUE_H */
+--- a/net/core/skbuff.c
++++ b/net/core/skbuff.c
+@@ -71,6 +71,9 @@
+ 
+ static struct kmem_cache *skbuff_head_cache __read_mostly;
+ static struct kmem_cache *skbuff_fclone_cache __read_mostly;
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++static struct kmem_cache *skbuff_cb_store_cache __read_mostly;
++#endif
+ 
+ static void sock_pipe_buf_release(struct pipe_inode_info *pipe,
+ 				  struct pipe_buffer *buf)
+@@ -90,6 +93,80 @@ static int sock_pipe_buf_steal(struct pi
+ 	return 1;
+ }
+ 
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++/* Control buffer save/restore for IMQ devices */
++struct skb_cb_table {
++	void			*cb_next;
++	atomic_t		refcnt;
++	char      		cb[48];
++};
 +
-+#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
-+err4:
-+	nf_unregister_hook(&imq_ingress_ipv6);
-+err3:
-+	nf_unregister_hook(&imq_egress_ipv4);
-+#endif
-+err2:
-+	nf_unregister_hook(&imq_ingress_ipv4);
-+err1:
-+	nf_unregister_queue_imq_handler();
-+	return err;
-+}
++static DEFINE_SPINLOCK(skb_cb_store_lock);
 +
-+static int __init imq_init_one(int index)
++int skb_save_cb(struct sk_buff *skb)
 +{
-+	struct net_device *dev;
-+	int ret;
++	struct skb_cb_table *next;
 +
-+	dev = alloc_netdev(0, "imq%d", imq_setup);
-+	if (!dev)
++	next = kmem_cache_alloc(skbuff_cb_store_cache, GFP_ATOMIC);
++	if (!next)
 +		return -ENOMEM;
 +
-+	ret = dev_alloc_name(dev, dev->name);
-+	if (ret < 0)
-+		goto fail;
++	BUILD_BUG_ON(sizeof(skb->cb) != sizeof(next->cb));
 +
-+	dev->rtnl_link_ops = &imq_link_ops;
-+	ret = register_netdevice(dev);
-+	if (ret < 0)
-+		goto fail;
++	memcpy(next->cb, skb->cb, sizeof(skb->cb));
++	next->cb_next = skb->cb_next;
++
++	atomic_set(&next->refcnt, 1);
 +
++	skb->cb_next = next;
 +	return 0;
-+fail:
-+	free_netdev(dev);
-+	return ret;
 +}
++EXPORT_SYMBOL(skb_save_cb);
 +
-+static int __init imq_init_devs(void)
++int skb_restore_cb(struct sk_buff *skb)
 +{
-+	int err, i;
-+
-+	if (numdevs < 1 || numdevs > IMQ_MAX_DEVS) {
-+		printk(KERN_ERR "IMQ: numdevs has to be betweed 1 and %u\n",
-+		       IMQ_MAX_DEVS);
-+		return -EINVAL;
-+	}
-+
-+	rtnl_lock();
-+	err = __rtnl_link_register(&imq_link_ops);
-+
-+	for (i = 0; i < numdevs && !err; i++)
-+		err = imq_init_one(i);
++	struct skb_cb_table *next;
 +
-+	if (err) {
-+		__rtnl_link_unregister(&imq_link_ops);
-+		memset(imq_devs_cache, 0, sizeof(imq_devs_cache));
-+	}
-+	rtnl_unlock();
++	if (!skb->cb_next)
++		return 0;
 +
-+	return err;
-+}
++	next = skb->cb_next;
 +
-+static int __init imq_init_module(void)
-+{
-+	int err;
++	BUILD_BUG_ON(sizeof(skb->cb) != sizeof(next->cb));
 +
-+#if defined(CONFIG_IMQ_NUM_DEVS)
-+	BUILD_BUG_ON(CONFIG_IMQ_NUM_DEVS > 16);
-+	BUILD_BUG_ON(CONFIG_IMQ_NUM_DEVS < 2);
-+	BUILD_BUG_ON(CONFIG_IMQ_NUM_DEVS - 1 > IMQ_F_IFMASK);
-+#endif
++	memcpy(skb->cb, next->cb, sizeof(skb->cb));
++	skb->cb_next = next->cb_next;
 +
-+	err = imq_init_devs();
-+	if (err) {
-+		printk(KERN_ERR "IMQ: Error trying imq_init_devs(net)\n");
-+		return err;
-+	}
++	spin_lock(&skb_cb_store_lock);
 +
-+	err = imq_init_hooks();
-+	if (err) {
-+		printk(KERN_ERR "IMQ: Error trying imq_init_hooks()\n");
-+		rtnl_link_unregister(&imq_link_ops);
-+		memset(imq_devs_cache, 0, sizeof(imq_devs_cache));
-+		return err;
++	if (atomic_dec_and_test(&next->refcnt)) {
++		kmem_cache_free(skbuff_cb_store_cache, next);
 +	}
 +
-+	printk(KERN_INFO "IMQ driver loaded successfully.\n");
-+
-+#if defined(CONFIG_IMQ_BEHAVIOR_BA) || defined(CONFIG_IMQ_BEHAVIOR_BB)
-+	printk(KERN_INFO "\tHooking IMQ before NAT on PREROUTING.\n");
-+#else
-+	printk(KERN_INFO "\tHooking IMQ after NAT on PREROUTING.\n");
-+#endif
-+#if defined(CONFIG_IMQ_BEHAVIOR_AB) || defined(CONFIG_IMQ_BEHAVIOR_BB)
-+	printk(KERN_INFO "\tHooking IMQ before NAT on POSTROUTING.\n");
-+#else
-+	printk(KERN_INFO "\tHooking IMQ after NAT on POSTROUTING.\n");
-+#endif
++	spin_unlock(&skb_cb_store_lock);
 +
 +	return 0;
 +}
++EXPORT_SYMBOL(skb_restore_cb);
 +
-+static void __exit imq_unhook(void)
-+{
-+#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
-+	nf_unregister_hook(&imq_ingress_ipv6);
-+	nf_unregister_hook(&imq_egress_ipv6);
-+#endif
-+	nf_unregister_hook(&imq_ingress_ipv4);
-+	nf_unregister_hook(&imq_egress_ipv4);
-+
-+	nf_unregister_queue_imq_handler();
-+}
-+
-+static void __exit imq_cleanup_devs(void)
++static void skb_copy_stored_cb(struct sk_buff *new, struct sk_buff *old)
 +{
-+	rtnl_link_unregister(&imq_link_ops);
-+	memset(imq_devs_cache, 0, sizeof(imq_devs_cache));
-+}
++	struct skb_cb_table *next;
 +
-+static void __exit imq_exit_module(void)
-+{
-+	imq_unhook();
-+	imq_cleanup_devs();
-+	printk(KERN_INFO "IMQ driver unloaded successfully.\n");
-+}
++	if (!old->cb_next) {
++		new->cb_next = 0;
++		return;
++	}
 +
-+module_init(imq_init_module);
-+module_exit(imq_exit_module);
++	spin_lock(&skb_cb_store_lock);
 +
-+module_param(numdevs, int, 0);
-+MODULE_PARM_DESC(numdevs, "number of IMQ devices (how many imq* devices will "
-+			"be created)");
-+MODULE_AUTHOR("http://www.linuximq.net");
-+MODULE_DESCRIPTION("Pseudo-driver for the intermediate queue device. See "
-+			"http://www.linuximq.net/ for more information.");
-+MODULE_LICENSE("GPL");
-+MODULE_ALIAS_RTNL_LINK("imq");
++	next = old->cb_next;
++	atomic_inc(&next->refcnt);
++	new->cb_next = next;
 +
---- a/drivers/net/Kconfig
-+++ b/drivers/net/Kconfig
-@@ -119,6 +119,129 @@ config EQUALIZER
- 	  To compile this driver as a module, choose M here: the module
- 	  will be called eql.  If unsure, say N.
++	spin_unlock(&skb_cb_store_lock);
++}
++#endif
  
-+config IMQ
-+	tristate "IMQ (intermediate queueing device) support"
-+	depends on NETDEVICES && NETFILTER
-+	---help---
-+	  The IMQ device(s) is used as placeholder for QoS queueing
-+	  disciplines. Every packet entering/leaving the IP stack can be
-+	  directed through the IMQ device where it's enqueued/dequeued to the
-+	  attached qdisc. This allows you to treat network devices as classes
-+	  and distribute bandwidth among them. Iptables is used to specify
-+	  through which IMQ device, if any, packets travel.
+ /* Pipe buffer operations for a socket. */
+ static struct pipe_buf_operations sock_pipe_buf_ops = {
+@@ -389,6 +466,15 @@ static void skb_release_head_state(struc
+ 		WARN_ON(in_irq());
+ 		skb->destructor(skb);
+ 	}
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++	/* This should not happen. When it does, avoid memleak by restoring
++	the chain of cb-backups. */
++	while(skb->cb_next != NULL) {
++		printk(KERN_WARNING "kfree_skb: skb->cb_next: %08x\n",
++			skb->cb_next);
++		skb_restore_cb(skb);
++	}
++#endif
+ #if defined(CONFIG_NF_CONNTRACK) || defined(CONFIG_NF_CONNTRACK_MODULE)
+ 	nf_conntrack_put(skb->nfct);
+ 	nf_conntrack_put_reasm(skb->nfct_reasm);
+@@ -526,6 +612,9 @@ static void __copy_skb_header(struct sk_
+ 	new->sp			= secpath_get(old->sp);
+ #endif
+ 	memcpy(new->cb, old->cb, sizeof(old->cb));
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++	skb_copy_stored_cb(new, old);
++#endif
+ 	new->csum_start		= old->csum_start;
+ 	new->csum_offset	= old->csum_offset;
+ 	new->local_df		= old->local_df;
+@@ -2769,6 +2858,13 @@ void __init skb_init(void)
+ 						0,
+ 						SLAB_HWCACHE_ALIGN|SLAB_PANIC,
+ 						NULL);
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++	skbuff_cb_store_cache = kmem_cache_create("skbuff_cb_store_cache",
++						  sizeof(struct skb_cb_table),
++						  0,
++						  SLAB_HWCACHE_ALIGN|SLAB_PANIC,
++						  NULL);
++#endif
+ }
+ 
+ /**
+--- a/net/netfilter/Kconfig
++++ b/net/netfilter/Kconfig
+@@ -396,6 +396,18 @@ config NETFILTER_XT_TARGET_LED
+ 	  For more information on the LEDs available on your system, see
+ 	  Documentation/leds-class.txt
+ 
++config NETFILTER_XT_TARGET_IMQ
++        tristate '"IMQ" target support'
++	depends on NETFILTER_XTABLES
++	depends on IP_NF_MANGLE || IP6_NF_MANGLE
++	select IMQ
++	default m if NETFILTER_ADVANCED=n
++        help
++          This option adds a `IMQ' target which is used to specify if and
++          to which imq device packets should get enqueued/dequeued.
 +
-+	  More information at: http://www.linuximq.net/
++          To compile it as a module, choose M here.  If unsure, say N.
 +
-+	  To compile this driver as a module, choose M here: the module
-+	  will be called imq.  If unsure, say N.
+ config NETFILTER_XT_TARGET_MARK
+ 	tristate '"MARK" target support'
+ 	default m if NETFILTER_ADVANCED=n
+--- a/net/netfilter/Makefile
++++ b/net/netfilter/Makefile
+@@ -46,6 +46,7 @@ obj-$(CONFIG_NETFILTER_XT_TARGET_CONNMAR
+ obj-$(CONFIG_NETFILTER_XT_TARGET_CONNSECMARK) += xt_CONNSECMARK.o
+ obj-$(CONFIG_NETFILTER_XT_TARGET_DSCP) += xt_DSCP.o
+ obj-$(CONFIG_NETFILTER_XT_TARGET_HL) += xt_HL.o
++obj-$(CONFIG_NETFILTER_XT_TARGET_IMQ) += xt_IMQ.o
+ obj-$(CONFIG_NETFILTER_XT_TARGET_LED) += xt_LED.o
+ obj-$(CONFIG_NETFILTER_XT_TARGET_MARK) += xt_MARK.o
+ obj-$(CONFIG_NETFILTER_XT_TARGET_NFLOG) += xt_NFLOG.o
+--- a/net/netfilter/nf_queue.c
++++ b/net/netfilter/nf_queue.c
+@@ -20,6 +20,26 @@ static const struct nf_queue_handler *qu
+ 
+ static DEFINE_MUTEX(queue_handler_mutex);
+ 
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++static const struct nf_queue_handler *queue_imq_handler;
 +
-+choice
-+	prompt "IMQ behavior (PRE/POSTROUTING)"
-+	depends on IMQ
-+	default IMQ_BEHAVIOR_AB
-+	help
++void nf_register_queue_imq_handler(const struct nf_queue_handler *qh)
++{
++	mutex_lock(&queue_handler_mutex);
++	rcu_assign_pointer(queue_imq_handler, qh);
++	mutex_unlock(&queue_handler_mutex);
++}
++EXPORT_SYMBOL(nf_register_queue_imq_handler);
 +
-+		This settings defines how IMQ behaves in respect to its
-+		hooking in PREROUTING and POSTROUTING.
++void nf_unregister_queue_imq_handler(void)
++{
++	mutex_lock(&queue_handler_mutex);
++	rcu_assign_pointer(queue_imq_handler, NULL);
++	mutex_unlock(&queue_handler_mutex);
++}
++EXPORT_SYMBOL(nf_unregister_queue_imq_handler);
++#endif
 +
-+		IMQ can work in any of the following ways:
+ /* return EBUSY when somebody else is registered, return EEXIST if the
+  * same handler is registered, return 0 in case of success. */
+ int nf_register_queue_handler(u_int8_t pf, const struct nf_queue_handler *qh)
+@@ -80,7 +100,7 @@ void nf_unregister_queue_handlers(const
+ }
+ EXPORT_SYMBOL_GPL(nf_unregister_queue_handlers);
+ 
+-static void nf_queue_entry_release_refs(struct nf_queue_entry *entry)
++void nf_queue_entry_release_refs(struct nf_queue_entry *entry)
+ {
+ 	/* Release those devices we held, or Alexey will kill me. */
+ 	if (entry->indev)
+@@ -100,6 +120,7 @@ static void nf_queue_entry_release_refs(
+ 	/* Drop reference to owner of hook which queued us. */
+ 	module_put(entry->elem->owner);
+ }
++EXPORT_SYMBOL_GPL(nf_queue_entry_release_refs);
+ 
+ /*
+  * Any packet that leaves via this function must come back
+@@ -121,12 +142,26 @@ static int __nf_queue(struct sk_buff *sk
+ #endif
+ 	const struct nf_afinfo *afinfo;
+ 	const struct nf_queue_handler *qh;
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++	const struct nf_queue_handler *qih = NULL;
++#endif
+ 
+ 	/* QUEUE == DROP if noone is waiting, to be safe. */
+ 	rcu_read_lock();
+ 
+ 	qh = rcu_dereference(queue_handler[pf]);
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
++	if (pf == PF_INET || pf == PF_INET6)
++#else
++	if (pf == PF_INET)
++#endif
++		qih = rcu_dereference(queue_imq_handler);
 +
-+		    PREROUTING   |      POSTROUTING
-+		-----------------|-------------------
-+		#1  After NAT    |      After NAT
-+		#2  After NAT    |      Before NAT
-+		#3  Before NAT   |      After NAT
-+		#4  Before NAT   |      Before NAT
++	if (!qh && !qih)
++#else /* !IMQ */
+ 	if (!qh)
++#endif
+ 		goto err_unlock;
+ 
+ 	afinfo = nf_get_afinfo(pf);
+@@ -145,6 +180,10 @@ static int __nf_queue(struct sk_buff *sk
+ 		.indev	= indev,
+ 		.outdev	= outdev,
+ 		.okfn	= okfn,
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++		.next_outfn = qh ? qh->outfn : NULL,
++		.next_queuenum = queuenum,
++#endif
+ 	};
+ 
+ 	/* If it's going away, ignore hook. */
+@@ -170,8 +209,19 @@ static int __nf_queue(struct sk_buff *sk
+ 	}
+ #endif
+ 	afinfo->saveroute(skb, entry);
 +
-+		The default behavior is to hook before NAT on PREROUTING
-+		and after NAT on POSTROUTING (#3).
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++	if (qih) {
++		status = qih->outfn(entry, queuenum);
++		goto imq_skip_queue;
++	}
++#endif
 +
-+		This settings are specially usefull when trying to use IMQ
-+		to shape NATed clients.
+ 	status = qh->outfn(entry, queuenum);
+ 
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++imq_skip_queue:
++#endif
+ 	rcu_read_unlock();
+ 
+ 	if (status < 0) {
+--- /dev/null
++++ b/net/netfilter/xt_IMQ.c
+@@ -0,0 +1,73 @@
++/*
++ * This target marks packets to be enqueued to an imq device
++ */
++#include <linux/module.h>
++#include <linux/skbuff.h>
++#include <linux/netfilter/x_tables.h>
++#include <linux/netfilter/xt_IMQ.h>
++#include <linux/imq.h>
 +
-+		More information can be found at: www.linuximq.net
++static unsigned int imq_target(struct sk_buff *pskb,
++				const struct xt_target_param *par)
++{
++	const struct xt_imq_info *mr = par->targinfo;
 +
-+		If not sure leave the default settings alone.
++	pskb->imq_flags = (mr->todev & IMQ_F_IFMASK) | IMQ_F_ENQUEUE;
 +
-+config IMQ_BEHAVIOR_AA
-+	bool "IMQ AA"
-+	help
-+		This settings defines how IMQ behaves in respect to its
-+		hooking in PREROUTING and POSTROUTING.
++	return XT_CONTINUE;
++}
 +
-+		Choosing this option will make IMQ hook like this:
++static bool imq_checkentry(const struct xt_tgchk_param *par)
++{
++	struct xt_imq_info *mr = par->targinfo;
 +
-+		PREROUTING:   After NAT
-+		POSTROUTING:  After NAT
++	if (mr->todev > IMQ_MAX_DEVS - 1) {
++		printk(KERN_WARNING
++		       "IMQ: invalid device specified, highest is %u\n",
++		       IMQ_MAX_DEVS - 1);
++		return 0;
++	}
 +
-+		More information can be found at: www.linuximq.net
++	return 1;
++}
 +
-+		If not sure leave the default settings alone.
++static struct xt_target xt_imq_reg[] __read_mostly = {
++	{
++		.name           = "IMQ",
++		.family		= AF_INET,
++		.checkentry     = imq_checkentry,
++		.target         = imq_target,
++		.targetsize	= sizeof(struct xt_imq_info),
++		.table		= "mangle",
++		.me             = THIS_MODULE
++	},
++	{
++		.name           = "IMQ",
++		.family		= AF_INET6,
++		.checkentry     = imq_checkentry,
++		.target         = imq_target,
++		.targetsize	= sizeof(struct xt_imq_info),
++		.table		= "mangle",
++		.me             = THIS_MODULE
++	},
++};
 +
-+config IMQ_BEHAVIOR_AB
-+	bool "IMQ AB"
-+	help
-+		This settings defines how IMQ behaves in respect to its
-+		hooking in PREROUTING and POSTROUTING.
++static int __init imq_init(void)
++{
++	return xt_register_targets(xt_imq_reg, ARRAY_SIZE(xt_imq_reg));
++}
 +
-+		Choosing this option will make IMQ hook like this:
++static void __exit imq_fini(void)
++{
++	xt_unregister_targets(xt_imq_reg, ARRAY_SIZE(xt_imq_reg));
++}
 +
-+		PREROUTING:   After NAT
-+		POSTROUTING:  Before NAT
++module_init(imq_init);
++module_exit(imq_fini);
 +
-+		More information can be found at: www.linuximq.net
++MODULE_AUTHOR("http://www.linuximq.net");
++MODULE_DESCRIPTION("Pseudo-driver for the intermediate queue device. See http://www.linuximq.net/ for more information.");
++MODULE_LICENSE("GPL");
++MODULE_ALIAS("ipt_IMQ");
++MODULE_ALIAS("ip6t_IMQ");
 +
-+		If not sure leave the default settings alone.
+--- /dev/null	2010-05-13 10:11:58.394584532 -0400
++++ b/drivers/net/imq.c	2010-07-30 16:43:35.000000000 -0400
+@@ -0,0 +1,820 @@
++/*
++ *             Pseudo-driver for the intermediate queue device.
++ *
++ *             This program is free software; you can redistribute it and/or
++ *             modify it under the terms of the GNU General Public License
++ *             as published by the Free Software Foundation; either version
++ *             2 of the License, or (at your option) any later version.
++ *
++ * Authors:    Patrick McHardy, <kaber@trash.net>
++ *
++ *            The first version was written by Martin Devera, <devik@cdi.cz>
++ *
++ * Credits:    Jan Rafaj <imq2t@cedric.vabo.cz>
++ *              - Update patch to 2.4.21
++ *             Sebastian Strollo <sstrollo@nortelnetworks.com>
++ *              - Fix "Dead-loop on netdevice imq"-issue
++ *             Marcel Sebek <sebek64@post.cz>
++ *              - Update to 2.6.2-rc1
++ *
++ *	       After some time of inactivity there is a group taking care
++ *	       of IMQ again: http://www.linuximq.net
++ *
++ *
++ *	       2004/06/30 - New version of IMQ patch to kernels <=2.6.7
++ *             including the following changes:
++ *
++ *	       - Correction of ipv6 support "+"s issue (Hasso Tepper)
++ *	       - Correction of imq_init_devs() issue that resulted in
++ *	       kernel OOPS unloading IMQ as module (Norbert Buchmuller)
++ *	       - Addition of functionality to choose number of IMQ devices
++ *	       during kernel config (Andre Correa)
++ *	       - Addition of functionality to choose how IMQ hooks on
++ *	       PRE and POSTROUTING (after or before NAT) (Andre Correa)
++ *	       - Cosmetic corrections (Norbert Buchmuller) (Andre Correa)
++ *
++ *
++ *             2005/12/16 - IMQ versions between 2.6.7 and 2.6.13 were
++ *             released with almost no problems. 2.6.14-x was released
++ *             with some important changes: nfcache was removed; After
++ *             some weeks of trouble we figured out that some IMQ fields
++ *             in skb were missing in skbuff.c - skb_clone and copy_skb_header.
++ *             These functions are correctly patched by this new patch version.
++ *
++ *             Thanks for all who helped to figure out all the problems with
++ *             2.6.14.x: Patrick McHardy, Rune Kock, VeNoMouS, Max CtRiX,
++ *             Kevin Shanahan, Richard Lucassen, Valery Dachev (hopefully
++ *             I didn't forget anybody). I apologize again for my lack of time.
++ *
++ *
++ *             2008/06/17 - 2.6.25 - Changed imq.c to use qdisc_run() instead
++ *             of qdisc_restart() and moved qdisc_run() to tasklet to avoid
++ *             recursive locking. New initialization routines to fix 'rmmod' not
++ *             working anymore. Used code from ifb.c. (Jussi Kivilinna)
++ *
++ *             2008/08/06 - 2.6.26 - (JK)
++ *              - Replaced tasklet with 'netif_schedule()'.
++ *              - Cleaned up and added comments for imq_nf_queue().
++ *
++ *             2009/04/12
++ *              - Add skb_save_cb/skb_restore_cb helper functions for backuping
++ *                control buffer. This is needed because qdisc-layer on kernels
++ *                2.6.27 and newer overwrite control buffer. (Jussi Kivilinna)
++ *              - Add better locking for IMQ device. Hopefully this will solve
++ *                SMP issues. (Jussi Kivilinna)
++ *              - Port to 2.6.27
++ *              - Port to 2.6.28
++ *              - Port to 2.6.29 + fix rmmod not working
++ *
++ *             2009/04/20 - (Jussi Kivilinna)
++ *              - Use netdevice feature flags to avoid extra packet handling
++ *                by core networking layer and possibly increase performance.
++ *
++ *	       Also, many thanks to pablo Sebastian Greco for making the initial
++ *	       patch and to those who helped the testing.
++ *
++ *             More info at: http://www.linuximq.net/ (Andre Correa)
++ */
 +
-+config IMQ_BEHAVIOR_BA
-+	bool "IMQ BA"
-+	help
-+		This settings defines how IMQ behaves in respect to its
-+		hooking in PREROUTING and POSTROUTING.
++#include <linux/module.h>
++#include <linux/kernel.h>
++#include <linux/moduleparam.h>
++#include <linux/list.h>
++#include <linux/skbuff.h>
++#include <linux/netdevice.h>
++#include <linux/etherdevice.h>
++#include <linux/rtnetlink.h>
++#include <linux/if_arp.h>
++#include <linux/netfilter.h>
++#include <linux/netfilter_ipv4.h>
++#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
++	#include <linux/netfilter_ipv6.h>
++#endif
++#include <linux/imq.h>
++#include <net/pkt_sched.h>
++#include <net/netfilter/nf_queue.h>
 +
-+		Choosing this option will make IMQ hook like this:
++static nf_hookfn imq_nf_hook;
 +
-+		PREROUTING:   Before NAT
-+		POSTROUTING:  After NAT
 +
-+		More information can be found at: www.linuximq.net
++#if defined(CONFIG_IMQ_NUM_DEVS)
++static unsigned int numdevs = CONFIG_IMQ_NUM_DEVS;
++#else
++static unsigned int numdevs = IMQ_MAX_DEVS;
++#endif
 +
-+		If not sure leave the default settings alone.
++static DEFINE_SPINLOCK(imq_nf_queue_lock);
 +
-+config IMQ_BEHAVIOR_BB
-+	bool "IMQ BB"
-+	help
-+		This settings defines how IMQ behaves in respect to its
-+		hooking in PREROUTING and POSTROUTING.
++static struct net_device *imq_devs_cache[IMQ_MAX_DEVS];
 +
-+		Choosing this option will make IMQ hook like this:
 +
-+		PREROUTING:   Before NAT
-+		POSTROUTING:  Before NAT
++static struct net_device_stats *imq_get_stats(struct net_device *dev)
++{
++	return &dev->stats;
++}
 +
-+		More information can be found at: www.linuximq.net
++/* called for packets kfree'd in qdiscs at places other than enqueue */
++static void imq_skb_destructor(struct sk_buff *skb)
++{
++	struct nf_queue_entry *entry = skb->nf_queue_entry;
 +
-+		If not sure leave the default settings alone.
++	if (entry) {
++		nf_queue_entry_release_refs(entry);
++		kfree(entry);
++	}
 +
-+endchoice
++	skb_restore_cb(skb); /* kfree backup */
++}
 +
-+config IMQ_NUM_DEVS
++static void imq_nf_reinject(struct nf_queue_entry *entry, unsigned int verdict)
++{
++	int status;
 +
-+	int "Number of IMQ devices"
-+	range 2 16
-+	depends on IMQ
-+	default "16"
-+	help
++	if (!entry->next_outfn) {
++		spin_lock_bh(&imq_nf_queue_lock);
++		nf_reinject(entry, verdict);
++		spin_unlock_bh(&imq_nf_queue_lock);
++		return;
++	}
++
++	rcu_read_lock();
++	local_bh_disable();
++	status = entry->next_outfn(entry, entry->next_queuenum);
++	local_bh_enable();
++	if (status < 0) {
++		nf_queue_entry_release_refs(entry);
++		kfree_skb(entry->skb);
++		kfree(entry);
++	}
++
++	rcu_read_unlock();
++}
++
++static int imq_dev_xmit(struct sk_buff *skb, struct net_device *dev)
++{
++	dev->stats.tx_bytes += skb->len;
++	dev->stats.tx_packets++;
++
++	skb->imq_flags = 0;
++	skb->destructor = NULL;
++
++	skb_restore_cb(skb); /* restore skb->cb */
++
++	dev->trans_start = jiffies;
++	imq_nf_reinject(skb->nf_queue_entry, NF_ACCEPT);
++	return 0;
++}
++
++static int imq_nf_queue(struct nf_queue_entry *entry, unsigned queue_num)
++{
++	struct net_device *dev;
++	struct sk_buff *skb_orig, *skb, *skb_shared;
++	struct Qdisc *q;
++	struct netdev_queue *txq;
++	int users, index;
++	int retval = -EINVAL;
 +
-+		This settings defines how many IMQ devices will be
-+		created.
++	index = entry->skb->imq_flags & IMQ_F_IFMASK;
++	if (unlikely(index > numdevs - 1)) {
++		if (net_ratelimit())
++			printk(KERN_WARNING
++			       "IMQ: invalid device specified, highest is %u\n",
++			       numdevs - 1);
++		retval = -EINVAL;
++		goto out;
++	}
 +
-+		The default value is 16.
++	/* check for imq device by index from cache */
++	dev = imq_devs_cache[index];
++	if (unlikely(!dev)) {
++		char buf[8];
 +
-+		More information can be found at: www.linuximq.net
++		/* get device by name and cache result */
++		snprintf(buf, sizeof(buf), "imq%d", index);
++		dev = dev_get_by_name(&init_net, buf);
++		if (!dev) {
++			/* not found ?!*/
++			BUG();
++			retval = -ENODEV;
++			goto out;
++		}
 +
-+		If not sure leave the default settings alone.
++		imq_devs_cache[index] = dev;
++		dev_put(dev);
++	}
 +
- config TUN
- 	tristate "Universal TUN/TAP device driver support"
- 	select CRC32
---- a/drivers/net/Makefile
-+++ b/drivers/net/Makefile
-@@ -152,6 +152,7 @@ obj-$(CONFIG_SLHC) += slhc.o
- obj-$(CONFIG_XEN_NETDEV_FRONTEND) += xen-netfront.o
- 
- obj-$(CONFIG_DUMMY) += dummy.o
-+obj-$(CONFIG_IMQ) += imq.o
- obj-$(CONFIG_IFB) += ifb.o
- obj-$(CONFIG_MACVLAN) += macvlan.o
- obj-$(CONFIG_DE600) += de600.o
---- /dev/null
-+++ b/include/linux/imq.h
-@@ -0,0 +1,13 @@
-+#ifndef _IMQ_H
-+#define _IMQ_H
++	if (unlikely(!(dev->flags & IFF_UP))) {
++		entry->skb->imq_flags = 0;
++		imq_nf_reinject(entry, NF_ACCEPT);
++		retval = 0;
++		goto out;
++	}
++	dev->last_rx = jiffies;
 +
-+/* IFMASK (16 device indexes, 0 to 15) and flag(s) fit in 5 bits */
-+#define IMQ_F_BITS	5
++	skb = entry->skb;
++	skb_orig = NULL;
 +
-+#define IMQ_F_IFMASK	0x0f
-+#define IMQ_F_ENQUEUE	0x10
++	/* skb has owner? => make clone */
++	if (unlikely(skb->destructor)) {
++		skb_orig = skb;
++		skb = skb_clone(skb, GFP_ATOMIC);
++		if (!skb) {
++			retval = -ENOMEM;
++			goto out;
++		}
++		entry->skb = skb;
++	}
 +
-+#define IMQ_MAX_DEVS	(IMQ_F_IFMASK + 1)
++	skb->nf_queue_entry = entry;
 +
-+#endif /* _IMQ_H */
++	dev->stats.rx_bytes += skb->len;
++	dev->stats.rx_packets++;
 +
---- /dev/null
-+++ b/include/linux/netfilter_ipv4/ipt_IMQ.h
-@@ -0,0 +1,10 @@
-+#ifndef _IPT_IMQ_H
-+#define _IPT_IMQ_H
++	txq = dev_pick_tx(dev, skb);
 +
-+/* Backwards compatibility for old userspace */
-+#include <linux/netfilter/xt_IMQ.h>
++	q = rcu_dereference(txq->qdisc);
++	if (unlikely(!q->enqueue))
++		goto packet_not_eaten_by_imq_dev;
 +
-+#define ipt_imq_info xt_imq_info
++	spin_lock_bh(qdisc_lock(q));
 +
-+#endif /* _IPT_IMQ_H */
++	users = atomic_read(&skb->users);
 +
---- /dev/null
-+++ b/include/linux/netfilter_ipv6/ip6t_IMQ.h
-@@ -0,0 +1,10 @@
-+#ifndef _IP6T_IMQ_H
-+#define _IP6T_IMQ_H
++	skb_shared = skb_get(skb); /* increase reference count by one */
++	skb_save_cb(skb_shared); /* backup skb->cb, as qdisc layer will
++					overwrite it */
++	qdisc_enqueue_root(skb_shared, q); /* might kfree_skb */
 +
-+/* Backwards compatibility for old userspace */
-+#include <linux/netfilter/xt_IMQ.h>
++	if (likely(atomic_read(&skb_shared->users) == users + 1)) {
++		kfree_skb(skb_shared); /* decrease reference count by one */
 +
-+#define ip6t_imq_info xt_imq_info
++		skb->destructor = &imq_skb_destructor;
 +
-+#endif /* _IP6T_IMQ_H */
++		/* cloned? */
++		if (skb_orig)
++			kfree_skb(skb_orig); /* free original */
 +
---- a/include/linux/skbuff.h
-+++ b/include/linux/skbuff.h
-@@ -28,6 +28,9 @@
- #include <linux/rcupdate.h>
- #include <linux/dmaengine.h>
- #include <linux/hrtimer.h>
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+#include <linux/imq.h>
-+#endif
- 
- /* Don't change this without changing skb_csum_unnecessary! */
- #define CHECKSUM_NONE 0
-@@ -333,6 +336,9 @@ struct sk_buff {
- 	 * first. This is owned by whoever has the skb queued ATM.
- 	 */
- 	char			cb[48];
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+	void			*cb_next;
-+#endif
- 
- 	unsigned int		len,
- 				data_len;
-@@ -363,6 +369,9 @@ struct sk_buff {
- 	struct nf_conntrack	*nfct;
- 	struct sk_buff		*nfct_reasm;
- #endif
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+	struct nf_queue_entry	*nf_queue_entry;
-+#endif
- #ifdef CONFIG_BRIDGE_NETFILTER
- 	struct nf_bridge_info	*nf_bridge;
- #endif
-@@ -383,6 +392,9 @@ struct sk_buff {
- 	__u8			requeue:1;
- #endif
- 	/* 0/13/14 bit hole */
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+	__u8			imq_flags:IMQ_F_BITS;
-+#endif
- 
- #ifdef CONFIG_NET_DMA
- 	dma_cookie_t		dma_cookie;
-@@ -423,6 +435,12 @@ extern void skb_dma_unmap(struct device
- 			  enum dma_data_direction dir);
- #endif
- 
++		spin_unlock_bh(qdisc_lock(q));
 +
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+extern int skb_save_cb(struct sk_buff *skb);
-+extern int skb_restore_cb(struct sk_buff *skb);
-+#endif
++		/* schedule qdisc dequeue */
++		__netif_schedule(q);
 +
- extern void kfree_skb(struct sk_buff *skb);
- extern void consume_skb(struct sk_buff *skb);
- extern void	       __kfree_skb(struct sk_buff *skb);
-@@ -1931,6 +1949,10 @@ static inline void __nf_copy(struct sk_b
- 	dst->nfct_reasm = src->nfct_reasm;
- 	nf_conntrack_get_reasm(src->nfct_reasm);
- #endif
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+	dst->imq_flags = src->imq_flags;
-+	dst->nf_queue_entry = src->nf_queue_entry;
-+#endif
- #ifdef CONFIG_BRIDGE_NETFILTER
- 	dst->nf_bridge  = src->nf_bridge;
- 	nf_bridge_get(src->nf_bridge);
---- a/net/core/dev.c
-+++ b/net/core/dev.c
-@@ -96,6 +96,9 @@
- #include <net/net_namespace.h>
- #include <net/sock.h>
- #include <linux/rtnetlink.h>
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+#include <linux/imq.h>
-+#endif
- #include <linux/proc_fs.h>
- #include <linux/seq_file.h>
- #include <linux/stat.h>
-@@ -1678,7 +1681,11 @@ int dev_hard_start_xmit(struct sk_buff *
- 	int rc;
- 
- 	if (likely(!skb->next)) {
--		if (!list_empty(&ptype_all))
-+		if (!list_empty(&ptype_all)
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+		    && !(skb->imq_flags & IMQ_F_ENQUEUE)
-+#endif
-+		    )
- 			dev_queue_xmit_nit(skb, dev);
- 
- 		if (netif_needs_gso(dev, skb)) {
-@@ -1749,8 +1756,7 @@ u16 skb_tx_hash(const struct net_device
- }
- EXPORT_SYMBOL(skb_tx_hash);
- 
--static struct netdev_queue *dev_pick_tx(struct net_device *dev,
--					struct sk_buff *skb)
-+struct netdev_queue *dev_pick_tx(struct net_device *dev, struct sk_buff *skb)
- {
- 	const struct net_device_ops *ops = dev->netdev_ops;
- 	u16 queue_index = 0;
-@@ -1763,6 +1769,7 @@ static struct netdev_queue *dev_pick_tx(
- 	skb_set_queue_mapping(skb, queue_index);
- 	return netdev_get_tx_queue(dev, queue_index);
- }
-+EXPORT_SYMBOL(dev_pick_tx);
- 
- /**
-  *	dev_queue_xmit - transmit a buffer
---- a/include/linux/netdevice.h
-+++ b/include/linux/netdevice.h
-@@ -1102,6 +1102,7 @@ extern int		dev_alloc_name(struct net_de
- extern int		dev_open(struct net_device *dev);
- extern int		dev_close(struct net_device *dev);
- extern void		dev_disable_lro(struct net_device *dev);
-+extern struct netdev_queue *dev_pick_tx(struct net_device *dev, struct sk_buff *skb);
- extern int		dev_queue_xmit(struct sk_buff *skb);
- extern int		register_netdevice(struct net_device *dev);
- extern void		unregister_netdevice(struct net_device *dev);
---- /dev/null
-+++ b/include/linux/netfilter/xt_IMQ.h
-@@ -0,0 +1,9 @@
-+#ifndef _XT_IMQ_H
-+#define _XT_IMQ_H
++		retval = 0;
++		goto out;
++	} else {
++		skb_restore_cb(skb_shared); /* restore skb->cb */
++		/* qdisc dropped packet and decreased skb reference count of
++		 * skb, so we don't really want to and try refree as that would
++		 * actually destroy the skb. */
++		spin_unlock_bh(qdisc_lock(q));
++		goto packet_not_eaten_by_imq_dev;
++	}
++
++packet_not_eaten_by_imq_dev:
++	/* cloned? restore original */
++	if (skb_orig) {
++		kfree_skb(skb);
++		entry->skb = skb_orig;
++	}
++	retval = -1;
++out:
++	return retval;
++}
 +
-+struct xt_imq_info {
-+	unsigned int todev;     /* target imq device */
++static struct nf_queue_handler nfqh = {
++	.name  = "imq",
++	.outfn = imq_nf_queue,
 +};
 +
-+#endif /* _XT_IMQ_H */
++static unsigned int imq_nf_hook(unsigned int hook, struct sk_buff *pskb,
++				const struct net_device *indev,
++				const struct net_device *outdev,
++				int (*okfn)(struct sk_buff *))
++{
++	if (pskb->imq_flags & IMQ_F_ENQUEUE)
++		return NF_QUEUE;
 +
---- a/include/net/netfilter/nf_queue.h
-+++ b/include/net/netfilter/nf_queue.h
-@@ -13,6 +13,12 @@ struct nf_queue_entry {
- 	struct net_device	*indev;
- 	struct net_device	*outdev;
- 	int			(*okfn)(struct sk_buff *);
++	return NF_ACCEPT;
++}
 +
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+	int			(*next_outfn)(struct nf_queue_entry *entry,
-+					      unsigned int queuenum);
-+	unsigned int		next_queuenum;
-+#endif
- };
- 
- #define nf_queue_entry_reroute(x) ((void *)x + sizeof(struct nf_queue_entry))
-@@ -30,5 +36,11 @@ extern int nf_unregister_queue_handler(u
- 				       const struct nf_queue_handler *qh);
- extern void nf_unregister_queue_handlers(const struct nf_queue_handler *qh);
- extern void nf_reinject(struct nf_queue_entry *entry, unsigned int verdict);
-+extern void nf_queue_entry_release_refs(struct nf_queue_entry *entry);
++static int imq_close(struct net_device *dev)
++{
++	netif_stop_queue(dev);
++	return 0;
++}
 +
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+extern void nf_register_queue_imq_handler(const struct nf_queue_handler *qh);
-+extern void nf_unregister_queue_imq_handler(void);
-+#endif
- 
- #endif /* _NF_QUEUE_H */
---- a/net/core/skbuff.c
-+++ b/net/core/skbuff.c
-@@ -71,6 +71,9 @@
- 
- static struct kmem_cache *skbuff_head_cache __read_mostly;
- static struct kmem_cache *skbuff_fclone_cache __read_mostly;
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+static struct kmem_cache *skbuff_cb_store_cache __read_mostly;
-+#endif
- 
- static void sock_pipe_buf_release(struct pipe_inode_info *pipe,
- 				  struct pipe_buffer *buf)
-@@ -90,6 +93,80 @@ static int sock_pipe_buf_steal(struct pi
- 	return 1;
- }
- 
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+/* Control buffer save/restore for IMQ devices */
-+struct skb_cb_table {
-+	void			*cb_next;
-+	atomic_t		refcnt;
-+	char      		cb[48];
++static int imq_open(struct net_device *dev)
++{
++	netif_start_queue(dev);
++	return 0;
++}
++
++static const struct net_device_ops imq_netdev_ops = {
++	.ndo_open		= imq_open,
++	.ndo_stop		= imq_close,
++	.ndo_start_xmit		= imq_dev_xmit,
++	.ndo_get_stats		= imq_get_stats,
 +};
 +
-+static DEFINE_SPINLOCK(skb_cb_store_lock);
++static void imq_setup(struct net_device *dev)
++{
++	dev->netdev_ops		= &imq_netdev_ops;
++	dev->type               = ARPHRD_VOID;
++	dev->mtu                = 16000;
++	dev->tx_queue_len       = 11000;
++	dev->flags              = IFF_NOARP;
++	dev->features           = NETIF_F_SG | NETIF_F_FRAGLIST |
++				  NETIF_F_GSO | NETIF_F_HW_CSUM |
++				  NETIF_F_HIGHDMA;
++}
 +
-+int skb_save_cb(struct sk_buff *skb)
++static int imq_validate(struct nlattr *tb[], struct nlattr *data[])
 +{
-+	struct skb_cb_table *next;
++	int ret = 0;
 +
-+	next = kmem_cache_alloc(skbuff_cb_store_cache, GFP_ATOMIC);
-+	if (!next)
-+		return -ENOMEM;
++	if (tb[IFLA_ADDRESS]) {
++		if (nla_len(tb[IFLA_ADDRESS]) != ETH_ALEN) {
++			ret = -EINVAL;
++			goto end;
++		}
++		if (!is_valid_ether_addr(nla_data(tb[IFLA_ADDRESS]))) {
++			ret = -EADDRNOTAVAIL;
++			goto end;
++		}
++	}
++	return 0;
++end:
++	printk(KERN_WARNING "IMQ: imq_validate failed (%d)\n", ret);
++	return ret;
++}
 +
-+	BUILD_BUG_ON(sizeof(skb->cb) != sizeof(next->cb));
++static struct rtnl_link_ops imq_link_ops __read_mostly = {
++	.kind		= "imq",
++	.priv_size	= 0,
++	.setup		= imq_setup,
++	.validate	= imq_validate,
++};
 +
-+	memcpy(next->cb, skb->cb, sizeof(skb->cb));
-+	next->cb_next = skb->cb_next;
 +
-+	atomic_set(&next->refcnt, 1);
 +
-+	skb->cb_next = next;
-+	return 0;
++static inline char *kernel_strdup(const char *str)
++{
++	char *tmp;
++	long int s;
++	s=strlen(str) + 1;
++	tmp = kmalloc(s, GFP_ATOMIC);
++	if (tmp != NULL)
++	{
++		memcpy(tmp, str, s);
++	}
++	return tmp;
 +}
-+EXPORT_SYMBOL(skb_save_cb);
 +
-+int skb_restore_cb(struct sk_buff *skb)
++/*
++ * line is the line to be parsed -- it is not modified in any way
++ * max_pieces indicates number of pieces to return, if negative this is determined dynamically
++ * include_remainder_at_max indicates whether the last piece, when max pieces are reached, 
++ * 	should be what it would normally be (0) or the entire remainder of the line (1)
++ * 	if max_pieces < 0 this parameter is ignored
++ *
++ *
++ * returns all non-separator pieces in a line
++ * result is dynamically allocated, MUST be freed after call-- even if 
++ * line is empty (you still get a valid char** pointer to to a NULL char*)
++ */
++char** split_on_separators(char* line, char* separators, int num_separators, int max_pieces, int include_remainder_at_max, unsigned long *num_pieces)
 +{
-+	struct skb_cb_table *next;
++	char** split;
++	
++	*num_pieces = 0;
++	if(line != NULL)
++	{
++		int split_index;
++		int non_separator_found;
++		char* dup_line;
++		char* start;
++
++		if(max_pieces < 0)
++		{
++			/* count number of separator characters in line -- this count + 1 is an upperbound on number of pieces */
++			int separator_count = 0;
++			int line_index;
++			for(line_index = 0; line[line_index] != '\0'; line_index++)
++			{
++				int sep_index;
++				int found = 0;
++				for(sep_index =0; found == 0 && sep_index < num_separators; sep_index++)
++				{
++					found = separators[sep_index] == line[line_index] ? 1 : 0;
++				}
++				separator_count = separator_count+ found;
++			}
++			max_pieces = separator_count + 1;
++		}
++		split = (char**)kmalloc((1+max_pieces)*sizeof(char*), GFP_ATOMIC);
++		split_index = 0;
++		split[split_index] = NULL;
++
++
++		dup_line = kernel_strdup(line);
++		start = dup_line;
++		non_separator_found = 0;
++		while(non_separator_found == 0)
++		{
++			int matches = 0;
++			int sep_index;
++			for(sep_index =0; sep_index < num_separators; sep_index++)
++			{
++				matches = matches == 1 || separators[sep_index] == start[0] ? 1 : 0;
++			}
++			non_separator_found = matches==0 || start[0] == '\0' ? 1 : 0;
++			if(non_separator_found == 0)
++			{
++				start++;
++			}
++		}
 +
-+	if (!skb->cb_next)
-+		return 0;
++		while(start[0] != '\0' && split_index < max_pieces)
++		{
++			/* find first separator index */
++			int first_separator_index = 0;
++			int separator_found = 0;
++			while(	separator_found == 0 )
++			{
++				int sep_index;
++				for(sep_index =0; separator_found == 0 && sep_index < num_separators; sep_index++)
++				{
++					separator_found = separators[sep_index] == start[first_separator_index] || start[first_separator_index] == '\0' ? 1 : 0;
++				}
++				if(separator_found == 0)
++				{
++					first_separator_index++;
++				}
++			}
++			
++			/* copy next piece to split array */
++			if(first_separator_index > 0)
++			{
++				char* next_piece = NULL;
++				if(split_index +1 < max_pieces || include_remainder_at_max <= 0)
++				{
++					next_piece = (char*)kmalloc((first_separator_index+1)*sizeof(char), GFP_ATOMIC);
++					memcpy(next_piece, start, first_separator_index);
++					next_piece[first_separator_index] = '\0';
++				}
++				else
++				{
++					next_piece = kernel_strdup(start);
++				}
++				split[split_index] = next_piece;
++				split[split_index+1] = NULL;
++				split_index++;
++			}
++
++
++			/* find next non-separator index, indicating start of next piece */
++			start = start+ first_separator_index;
++			non_separator_found = 0;
++			while(non_separator_found == 0)
++			{
++				int matches = 0;
++				int sep_index;
++				for(sep_index =0; sep_index < num_separators; sep_index++)
++				{
++					matches = matches == 1 || separators[sep_index] == start[0] ? 1 : 0;
++				}
++				non_separator_found = matches==0 || start[0] == '\0' ? 1 : 0;
++				if(non_separator_found == 0)
++				{
++					start++;
++				}
++			}
++		}
++		kfree(dup_line);
++		*num_pieces = split_index;
++	}
++	else
++	{
++		split = (char**)kmalloc((1)*sizeof(char*), GFP_ATOMIC);
++		split[0] = NULL;
++	}
++	return split;
++}
 +
-+	next = skb->cb_next;
 +
-+	BUILD_BUG_ON(sizeof(skb->cb) != sizeof(next->cb));
++/* returns number freed */
++int free_null_terminated_string_array(char** strs)
++{
++	unsigned long str_index = 0;
++	if(strs != NULL)
++	{
++		for(str_index=0; strs[str_index] != NULL; str_index++)
++		{
++			kfree(strs[str_index]);
++		}
++		kfree(strs);
++	}
++	return str_index;
++}
 +
-+	memcpy(skb->cb, next->cb, sizeof(skb->cb));
-+	skb->cb_next = next->cb_next;
 +
-+	spin_lock(&skb_cb_store_lock);
 +
-+	if (atomic_dec_and_test(&next->refcnt)) {
-+		kmem_cache_free(skbuff_cb_store_cache, next);
-+	}
 +
-+	spin_unlock(&skb_cb_store_lock);
 +
-+	return 0;
-+}
-+EXPORT_SYMBOL(skb_restore_cb);
++#if defined(CONFIG_IMQ_BEHAVIOR_BA) || defined(CONFIG_IMQ_BEHAVIOR_BB)
++	#define DEFAULT_PRE_TABLE "mangle"
++#else
++	#define DEFAULT_PRE_TABLE "nat"
++#endif
 +
-+static void skb_copy_stored_cb(struct sk_buff *new, struct sk_buff *old)
++#if defined(CONFIG_IMQ_BEHAVIOR_AA) || defined(CONFIG_IMQ_BEHAVIOR_BA)
++	#define DEFAULT_POST_TABLE "nat"
++#else
++	#define DEFAULT_POST_TABLE "mangle"
++#endif
++
++
++
++static char* hook_chains = "PREROUTING,POSTROUTING";
++static char* hook_tables = DEFAULT_PRE_TABLE "," DEFAULT_POST_TABLE;
++
++static struct nf_hook_ops* hook_list = NULL;
++static int hook_list_length = 0;
++
++
++static int __init imq_init_hooks(void)
 +{
-+	struct skb_cb_table *next;
 +
-+	if (!old->cb_next) {
-+		new->cb_next = 0;
-+		return;
-+	}
 +
-+	spin_lock(&skb_cb_store_lock);
++	char separators[4] = {',', ' ', '\t', '\0' };
++	unsigned long num_chains;
++	unsigned long num_tables;
++	char** chain_list = split_on_separators(hook_chains, separators, 3, -1, 0, &num_chains);
++	char** table_list = split_on_separators(hook_tables, separators, 3, -1, 0, &num_tables);
++	int hook_index = 0;
++	
++	nf_register_queue_imq_handler(&nfqh);
 +
-+	next = old->cb_next;
-+	atomic_inc(&next->refcnt);
-+	new->cb_next = next;
 +
-+	spin_unlock(&skb_cb_store_lock);
-+}
-+#endif
- 
- /* Pipe buffer operations for a socket. */
- static struct pipe_buf_operations sock_pipe_buf_ops = {
-@@ -389,6 +466,15 @@ static void skb_release_head_state(struc
- 		WARN_ON(in_irq());
- 		skb->destructor(skb);
- 	}
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+	/* This should not happen. When it does, avoid memleak by restoring
-+	the chain of cb-backups. */
-+	while(skb->cb_next != NULL) {
-+		printk(KERN_WARNING "kfree_skb: skb->cb_next: %08x\n",
-+			skb->cb_next);
-+		skb_restore_cb(skb);
++	hook_list_length = 0;
++	if(num_chains != num_tables)
++	{
++		printk("ERROR: must have same number of chains and tables\n");
++		return -1;
 +	}
-+#endif
- #if defined(CONFIG_NF_CONNTRACK) || defined(CONFIG_NF_CONNTRACK_MODULE)
- 	nf_conntrack_put(skb->nfct);
- 	nf_conntrack_put_reasm(skb->nfct_reasm);
-@@ -526,6 +612,9 @@ static void __copy_skb_header(struct sk_
- 	new->sp			= secpath_get(old->sp);
- #endif
- 	memcpy(new->cb, old->cb, sizeof(old->cb));
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+	skb_copy_stored_cb(new, old);
-+#endif
- 	new->csum_start		= old->csum_start;
- 	new->csum_offset	= old->csum_offset;
- 	new->local_df		= old->local_df;
-@@ -2769,6 +2858,13 @@ void __init skb_init(void)
- 						0,
- 						SLAB_HWCACHE_ALIGN|SLAB_PANIC,
- 						NULL);
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+	skbuff_cb_store_cache = kmem_cache_create("skbuff_cb_store_cache",
-+						  sizeof(struct skb_cb_table),
-+						  0,
-+						  SLAB_HWCACHE_ALIGN|SLAB_PANIC,
-+						  NULL);
-+#endif
- }
- 
- /**
---- a/net/netfilter/Kconfig
-+++ b/net/netfilter/Kconfig
-@@ -396,6 +396,18 @@ config NETFILTER_XT_TARGET_LED
- 	  For more information on the LEDs available on your system, see
- 	  Documentation/leds-class.txt
- 
-+config NETFILTER_XT_TARGET_IMQ
-+        tristate '"IMQ" target support'
-+	depends on NETFILTER_XTABLES
-+	depends on IP_NF_MANGLE || IP6_NF_MANGLE
-+	select IMQ
-+	default m if NETFILTER_ADVANCED=n
-+        help
-+          This option adds a `IMQ' target which is used to specify if and
-+          to which imq device packets should get enqueued/dequeued.
++	
++	/* we multiply by 2 here since we need hooks for both IPv4 and IPv6 */
++	hook_list = (struct nf_hook_ops*)kmalloc(sizeof(struct nf_hook_ops)*((num_chains*2)+1), GFP_ATOMIC); 
++	
++	
++	for(hook_index=0; hook_index < num_chains; hook_index++)
++	{
++		char* chain = chain_list[hook_index];
++		char* table = table_list[hook_index];
++		int valid = 0;
++		if(strcmp(chain, "PREROUTING") == 0 || strcmp(chain, "POSTROUTING") == 0 || strcmp(chain, "INPUT") == 0 || strcmp(chain, "FORWARD") == 0 || strcmp(chain, "OUTPUT") == 0)
++		{
++			if( 	strcmp(table, "mangle") == 0 || 
++				(strcmp(table, "nat") == 0 && strcmp(chain, "FORWARD") != 0 && strcmp(chain, "INPUT") != 0 ) || 
++				(strcmp(table, "filter") == 0 && strcmp(chain, "PREROUTING") != 0 && strcmp(chain, "POSTROUTING") != 0 )
++			  )
++			{
++				unsigned int chain_id = NF_INET_PRE_ROUTING;
++				int table_id = NF_IP_PRI_MANGLE;
++				int err = 0;
++
++				valid = 1;
++
++				if(strcmp(chain, "PREROUTING") == 0)
++				{
++					chain_id = NF_INET_PRE_ROUTING;
++				}
++				else if (strcmp(chain, "POSTROUTING") == 0)
++				{
++					chain_id = NF_INET_POST_ROUTING;
++				}
++				else if (strcmp(chain, "INPUT") == 0)
++				{
++					chain_id = NF_INET_LOCAL_IN;
++
++				}
++				else if (strcmp(chain, "FORWARD") == 0)
++				{
++					chain_id = NF_INET_FORWARD;
++
++				}
++				else if (strcmp(chain, "OUTPUT") == 0)
++				{
++					chain_id = NF_INET_LOCAL_OUT;
++				}
++
++				if(strcmp(table, "mangle") == 0)
++				{
++					table_id = NF_IP_PRI_MANGLE+1;
++				}
++				else if (strcmp(table, "nat") == 0 && strcmp(chain, "POSTROUTING") == 0)
++				{
++					table_id = NF_IP_PRI_NAT_SRC+1;
++				}
++				else if (strcmp(table, "nat") == 0 && strcmp(chain, "POSTROUTING") != 0)
++				{
++					table_id = NF_IP_PRI_NAT_DST+1;
++				}
++				else if (strcmp(table, "filter") == 0)
++				{
++					table_id = NF_IP_PRI_FILTER+1;
++				}
++				(hook_list[hook_list_length]).hook = imq_nf_hook;
++				(hook_list[hook_list_length]).owner = THIS_MODULE;
++				(hook_list[hook_list_length]).pf = PF_INET;
++				(hook_list[hook_list_length]).hooknum = chain_id;
++				(hook_list[hook_list_length]).priority = table_id;
++				err = nf_register_hook( (hook_list + hook_list_length) );
++				hook_list_length++;
++
++				#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
++					if(strcmp(table, "mangle") == 0)
++					{
++						table_id = NF_IP6_PRI_MANGLE+1;
++					}
++					else if (strcmp(table, "nat") == 0 && strcmp(chain, "POSTROUTING") == 0)
++					{
++						table_id = NF_IP6_PRI_NAT_SRC+1;
++					}
++					else if (strcmp(table, "nat") == 0 && strcmp(chain, "POSTROUTING") != 0)
++					{
++						table_id = NF_IP6_PRI_NAT_DST+1;
++					}
++					else if (strcmp(table, "filter") == 0)
++					{
++						table_id = NF_IP6_PRI_FILTER+1;
++					}
++
++					(hook_list[hook_list_length]).hook = imq_nf_hook;
++					(hook_list[hook_list_length]).owner = THIS_MODULE;
++					(hook_list[hook_list_length]).pf = PF_INET6;
++					(hook_list[hook_list_length]).hooknum = chain_id;
++					(hook_list[hook_list_length]).priority = table_id;
++					nf_register_hook( (hook_list + hook_list_length) );
++					hook_list_length++;
++				#endif
++
++
++				if(err)
++				{
++					printk(KERN_INFO "\tError hooking IMQ after %s on %s\n", table, chain);
++				}
++				else
++				{
++					printk(KERN_INFO "\tHooked IMQ after %s on %s\n", table, chain);
++				}
++
++			}
++		}
++		if(valid == 0)
++		{
++			printk("ERROR: invalid chain/table at index %d (%s/%s)\n", hook_index, chain, table);
++		}
++	}
++	free_null_terminated_string_array(chain_list);
++	free_null_terminated_string_array(table_list);
++
++	return 0;
 +
-+          To compile it as a module, choose M here.  If unsure, say N.
++}
 +
- config NETFILTER_XT_TARGET_MARK
- 	tristate '"MARK" target support'
- 	default m if NETFILTER_ADVANCED=n
---- a/net/netfilter/Makefile
-+++ b/net/netfilter/Makefile
-@@ -46,6 +46,7 @@ obj-$(CONFIG_NETFILTER_XT_TARGET_CONNMAR
- obj-$(CONFIG_NETFILTER_XT_TARGET_CONNSECMARK) += xt_CONNSECMARK.o
- obj-$(CONFIG_NETFILTER_XT_TARGET_DSCP) += xt_DSCP.o
- obj-$(CONFIG_NETFILTER_XT_TARGET_HL) += xt_HL.o
-+obj-$(CONFIG_NETFILTER_XT_TARGET_IMQ) += xt_IMQ.o
- obj-$(CONFIG_NETFILTER_XT_TARGET_LED) += xt_LED.o
- obj-$(CONFIG_NETFILTER_XT_TARGET_MARK) += xt_MARK.o
- obj-$(CONFIG_NETFILTER_XT_TARGET_NFLOG) += xt_NFLOG.o
---- a/net/netfilter/nf_queue.c
-+++ b/net/netfilter/nf_queue.c
-@@ -20,6 +20,26 @@ static const struct nf_queue_handler *qu
- 
- static DEFINE_MUTEX(queue_handler_mutex);
- 
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+static const struct nf_queue_handler *queue_imq_handler;
 +
-+void nf_register_queue_imq_handler(const struct nf_queue_handler *qh)
++
++
++static void __exit imq_unhook(void)
 +{
-+	mutex_lock(&queue_handler_mutex);
-+	rcu_assign_pointer(queue_imq_handler, qh);
-+	mutex_unlock(&queue_handler_mutex);
++
++	int hook_index = 0;
++	for(hook_index = 0; hook_index < hook_list_length; hook_index++)
++	{
++		nf_unregister_hook( (hook_list+hook_index) );
++	}
++	nf_unregister_queue_imq_handler();
++
++	kfree(hook_list);
++	hook_list_length = 0;
++
 +}
-+EXPORT_SYMBOL(nf_register_queue_imq_handler);
 +
-+void nf_unregister_queue_imq_handler(void)
++
++
++
++
++static int __init imq_init_one(int index)
 +{
-+	mutex_lock(&queue_handler_mutex);
-+	rcu_assign_pointer(queue_imq_handler, NULL);
-+	mutex_unlock(&queue_handler_mutex);
-+}
-+EXPORT_SYMBOL(nf_unregister_queue_imq_handler);
-+#endif
++	struct net_device *dev;
++	int ret;
 +
- /* return EBUSY when somebody else is registered, return EEXIST if the
-  * same handler is registered, return 0 in case of success. */
- int nf_register_queue_handler(u_int8_t pf, const struct nf_queue_handler *qh)
-@@ -80,7 +100,7 @@ void nf_unregister_queue_handlers(const
- }
- EXPORT_SYMBOL_GPL(nf_unregister_queue_handlers);
- 
--static void nf_queue_entry_release_refs(struct nf_queue_entry *entry)
-+void nf_queue_entry_release_refs(struct nf_queue_entry *entry)
- {
- 	/* Release those devices we held, or Alexey will kill me. */
- 	if (entry->indev)
-@@ -100,6 +120,7 @@ static void nf_queue_entry_release_refs(
- 	/* Drop reference to owner of hook which queued us. */
- 	module_put(entry->elem->owner);
- }
-+EXPORT_SYMBOL_GPL(nf_queue_entry_release_refs);
- 
- /*
-  * Any packet that leaves via this function must come back
-@@ -121,12 +142,26 @@ static int __nf_queue(struct sk_buff *sk
- #endif
- 	const struct nf_afinfo *afinfo;
- 	const struct nf_queue_handler *qh;
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+	const struct nf_queue_handler *qih = NULL;
-+#endif
- 
- 	/* QUEUE == DROP if noone is waiting, to be safe. */
- 	rcu_read_lock();
- 
- 	qh = rcu_dereference(queue_handler[pf]);
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
-+	if (pf == PF_INET || pf == PF_INET6)
-+#else
-+	if (pf == PF_INET)
-+#endif
-+		qih = rcu_dereference(queue_imq_handler);
++	dev = alloc_netdev(0, "imq%d", imq_setup);
++	if (!dev)
++		return -ENOMEM;
 +
-+	if (!qh && !qih)
-+#else /* !IMQ */
- 	if (!qh)
-+#endif
- 		goto err_unlock;
- 
- 	afinfo = nf_get_afinfo(pf);
-@@ -145,6 +180,10 @@ static int __nf_queue(struct sk_buff *sk
- 		.indev	= indev,
- 		.outdev	= outdev,
- 		.okfn	= okfn,
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+		.next_outfn = qh ? qh->outfn : NULL,
-+		.next_queuenum = queuenum,
-+#endif
- 	};
- 
- 	/* If it's going away, ignore hook. */
-@@ -170,8 +209,19 @@ static int __nf_queue(struct sk_buff *sk
- 	}
- #endif
- 	afinfo->saveroute(skb, entry);
++	ret = dev_alloc_name(dev, dev->name);
++	if (ret < 0)
++		goto fail;
 +
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+	if (qih) {
-+		status = qih->outfn(entry, queuenum);
-+		goto imq_skip_queue;
-+	}
-+#endif
++	dev->rtnl_link_ops = &imq_link_ops;
++	ret = register_netdevice(dev);
++	if (ret < 0)
++		goto fail;
 +
- 	status = qh->outfn(entry, queuenum);
- 
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+imq_skip_queue:
-+#endif
- 	rcu_read_unlock();
- 
- 	if (status < 0) {
---- /dev/null
-+++ b/net/netfilter/xt_IMQ.c
-@@ -0,0 +1,73 @@
-+/*
-+ * This target marks packets to be enqueued to an imq device
-+ */
-+#include <linux/module.h>
-+#include <linux/skbuff.h>
-+#include <linux/netfilter/x_tables.h>
-+#include <linux/netfilter/xt_IMQ.h>
-+#include <linux/imq.h>
++	return 0;
++fail:
++	free_netdev(dev);
++	return ret;
++}
 +
-+static unsigned int imq_target(struct sk_buff *pskb,
-+				const struct xt_target_param *par)
++static int __init imq_init_devs(void)
 +{
-+	const struct xt_imq_info *mr = par->targinfo;
++	int err, i;
 +
-+	pskb->imq_flags = (mr->todev & IMQ_F_IFMASK) | IMQ_F_ENQUEUE;
++	if (numdevs < 1 || numdevs > IMQ_MAX_DEVS) {
++		printk(KERN_ERR "IMQ: numdevs has to be betweed 1 and %u\n",
++		       IMQ_MAX_DEVS);
++		return -EINVAL;
++	}
 +
-+	return XT_CONTINUE;
++	rtnl_lock();
++	err = __rtnl_link_register(&imq_link_ops);
++
++	for (i = 0; i < numdevs && !err; i++)
++		err = imq_init_one(i);
++
++	if (err) {
++		__rtnl_link_unregister(&imq_link_ops);
++		memset(imq_devs_cache, 0, sizeof(imq_devs_cache));
++	}
++	rtnl_unlock();
++
++	return err;
 +}
 +
-+static bool imq_checkentry(const struct xt_tgchk_param *par)
++static int __init imq_init_module(void)
 +{
-+	struct xt_imq_info *mr = par->targinfo;
++	int err;
 +
-+	if (mr->todev > IMQ_MAX_DEVS - 1) {
-+		printk(KERN_WARNING
-+		       "IMQ: invalid device specified, highest is %u\n",
-+		       IMQ_MAX_DEVS - 1);
-+		return 0;
++#if defined(CONFIG_IMQ_NUM_DEVS)
++	BUILD_BUG_ON(CONFIG_IMQ_NUM_DEVS > 16);
++	BUILD_BUG_ON(CONFIG_IMQ_NUM_DEVS < 2);
++	BUILD_BUG_ON(CONFIG_IMQ_NUM_DEVS - 1 > IMQ_F_IFMASK);
++#endif
++
++	err = imq_init_devs();
++	if (err) {
++		printk(KERN_ERR "IMQ: Error trying imq_init_devs(net)\n");
++		return err;
 +	}
 +
-+	return 1;
++	err = imq_init_hooks();
++	if (err) {
++		printk(KERN_ERR "IMQ: Error trying imq_init_hooks()\n");
++		rtnl_link_unregister(&imq_link_ops);
++		memset(imq_devs_cache, 0, sizeof(imq_devs_cache));
++		return err;
++	}
++
++	printk(KERN_INFO "IMQ driver loaded successfully.\n");
++
++	return 0;
 +}
 +
-+static struct xt_target xt_imq_reg[] __read_mostly = {
-+	{
-+		.name           = "IMQ",
-+		.family		= AF_INET,
-+		.checkentry     = imq_checkentry,
-+		.target         = imq_target,
-+		.targetsize	= sizeof(struct xt_imq_info),
-+		.table		= "mangle",
-+		.me             = THIS_MODULE
-+	},
-+	{
-+		.name           = "IMQ",
-+		.family		= AF_INET6,
-+		.checkentry     = imq_checkentry,
-+		.target         = imq_target,
-+		.targetsize	= sizeof(struct xt_imq_info),
-+		.table		= "mangle",
-+		.me             = THIS_MODULE
-+	},
-+};
 +
-+static int __init imq_init(void)
++static void __exit imq_cleanup_devs(void)
 +{
-+	return xt_register_targets(xt_imq_reg, ARRAY_SIZE(xt_imq_reg));
++	rtnl_link_unregister(&imq_link_ops);
++	memset(imq_devs_cache, 0, sizeof(imq_devs_cache));
 +}
 +
-+static void __exit imq_fini(void)
++static void __exit imq_exit_module(void)
 +{
-+	xt_unregister_targets(xt_imq_reg, ARRAY_SIZE(xt_imq_reg));
++	imq_unhook();
++	imq_cleanup_devs();
++	printk(KERN_INFO "IMQ driver unloaded successfully.\n");
 +}
 +
-+module_init(imq_init);
-+module_exit(imq_fini);
++module_init(imq_init_module);
++module_exit(imq_exit_module);
++
++
++
++module_param(numdevs, int, 0);
++module_param(hook_chains, charp, 0);
++module_param(hook_tables, charp, 0);
++
++MODULE_PARM_DESC(numdevs, "number of IMQ devices (how many imq* devices will be created)");
++MODULE_PARM_DESC(hook_chains, "netfilter chains in which to insert hooks to IMQ");
++MODULE_PARM_DESC(hook_tables, "netfilter tables after which to insert hooks to IMQ");
++
++
 +
 +MODULE_AUTHOR("http://www.linuximq.net");
-+MODULE_DESCRIPTION("Pseudo-driver for the intermediate queue device. See http://www.linuximq.net/ for more information.");
++MODULE_DESCRIPTION("Pseudo-driver for the intermediate queue device. See "
++			"http://www.linuximq.net/ for more information.");
 +MODULE_LICENSE("GPL");
-+MODULE_ALIAS("ipt_IMQ");
-+MODULE_ALIAS("ip6t_IMQ");
++MODULE_ALIAS_RTNL_LINK("imq");
 +
--- backfire-orig/target/linux/generic-2.6/patches-2.6.32/150-netfilter_imq.patch	2010-07-30 16:54:01.000000000 -0400
+++ backfire/target/linux/generic-2.6/patches-2.6.32/150-netfilter_imq.patch	2010-07-30 16:59:35.000000000 -0400
@@ -1,1336 +1,1598 @@
---- /dev/null
-+++ b/drivers/net/imq.c
-@@ -0,0 +1,632 @@
-+/*
-+ *             Pseudo-driver for the intermediate queue device.
-+ *
-+ *             This program is free software; you can redistribute it and/or
-+ *             modify it under the terms of the GNU General Public License
-+ *             as published by the Free Software Foundation; either version
-+ *             2 of the License, or (at your option) any later version.
-+ *
-+ * Authors:    Patrick McHardy, <kaber@trash.net>
-+ *
-+ *            The first version was written by Martin Devera, <devik@cdi.cz>
-+ *
-+ * Credits:    Jan Rafaj <imq2t@cedric.vabo.cz>
-+ *              - Update patch to 2.4.21
-+ *             Sebastian Strollo <sstrollo@nortelnetworks.com>
-+ *              - Fix "Dead-loop on netdevice imq"-issue
-+ *             Marcel Sebek <sebek64@post.cz>
-+ *              - Update to 2.6.2-rc1
-+ *
-+ *	       After some time of inactivity there is a group taking care
-+ *	       of IMQ again: http://www.linuximq.net
-+ *
-+ *
-+ *	       2004/06/30 - New version of IMQ patch to kernels <=2.6.7
-+ *             including the following changes:
-+ *
-+ *	       - Correction of ipv6 support "+"s issue (Hasso Tepper)
-+ *	       - Correction of imq_init_devs() issue that resulted in
-+ *	       kernel OOPS unloading IMQ as module (Norbert Buchmuller)
-+ *	       - Addition of functionality to choose number of IMQ devices
-+ *	       during kernel config (Andre Correa)
-+ *	       - Addition of functionality to choose how IMQ hooks on
-+ *	       PRE and POSTROUTING (after or before NAT) (Andre Correa)
-+ *	       - Cosmetic corrections (Norbert Buchmuller) (Andre Correa)
-+ *
-+ *
-+ *             2005/12/16 - IMQ versions between 2.6.7 and 2.6.13 were
-+ *             released with almost no problems. 2.6.14-x was released
-+ *             with some important changes: nfcache was removed; After
-+ *             some weeks of trouble we figured out that some IMQ fields
-+ *             in skb were missing in skbuff.c - skb_clone and copy_skb_header.
-+ *             These functions are correctly patched by this new patch version.
-+ *
-+ *             Thanks for all who helped to figure out all the problems with
-+ *             2.6.14.x: Patrick McHardy, Rune Kock, VeNoMouS, Max CtRiX,
-+ *             Kevin Shanahan, Richard Lucassen, Valery Dachev (hopefully
-+ *             I didn't forget anybody). I apologize again for my lack of time.
-+ *
-+ *
-+ *             2008/06/17 - 2.6.25 - Changed imq.c to use qdisc_run() instead 
-+ *             of qdisc_restart() and moved qdisc_run() to tasklet to avoid
-+ *             recursive locking. New initialization routines to fix 'rmmod' not
-+ *             working anymore. Used code from ifb.c. (Jussi Kivilinna)
-+ *
-+ *             2008/08/06 - 2.6.26 - (JK)
-+ *              - Replaced tasklet with 'netif_schedule()'.
-+ *              - Cleaned up and added comments for imq_nf_queue().
-+ *
-+ *             2009/04/12
-+ *              - Add skb_save_cb/skb_restore_cb helper functions for backuping
-+ *                control buffer. This is needed because qdisc-layer on kernels
-+ *                2.6.27 and newer overwrite control buffer. (Jussi Kivilinna)
-+ *              - Add better locking for IMQ device. Hopefully this will solve
-+ *                SMP issues. (Jussi Kivilinna)
-+ *              - Port to 2.6.27
-+ *              - Port to 2.6.28
-+ *              - Port to 2.6.29 + fix rmmod not working
-+ *
-+ *             2009/04/20 - (Jussi Kivilinna)
-+ *              - Use netdevice feature flags to avoid extra packet handling
-+ *                by core networking layer and possibly increase performance.
-+ *
-+ *             2009/09/26 - (Jussi Kivilinna)
-+ *              - Add imq_nf_reinject_lockless to fix deadlock with
-+ *                imq_nf_queue/imq_nf_reinject.
-+ *
-+ *             2009/12/08 - (Jussi Kivilinna)
-+ *              - Port to 2.6.32
-+ *              - Add check for skb->nf_queue_entry==NULL in imq_dev_xmit()
-+ *              - Also add better error checking for skb->nf_queue_entry usage
-+ *
-+ *	       Also, many thanks to pablo Sebastian Greco for making the initial
-+ *	       patch and to those who helped the testing.
-+ *
-+ *             More info at: http://www.linuximq.net/ (Andre Correa)
-+ */
+--- a/drivers/net/Kconfig
++++ b/drivers/net/Kconfig
+@@ -109,6 +109,129 @@ config EQUALIZER
+ 	  To compile this driver as a module, choose M here: the module
+ 	  will be called eql.  If unsure, say N.
+ 
++config IMQ
++	tristate "IMQ (intermediate queueing device) support"
++	depends on NETDEVICES && NETFILTER
++	---help---
++	  The IMQ device(s) is used as placeholder for QoS queueing
++	  disciplines. Every packet entering/leaving the IP stack can be
++	  directed through the IMQ device where it's enqueued/dequeued to the
++	  attached qdisc. This allows you to treat network devices as classes
++	  and distribute bandwidth among them. Iptables is used to specify
++	  through which IMQ device, if any, packets travel.
 +
-+#include <linux/module.h>
-+#include <linux/kernel.h>
-+#include <linux/moduleparam.h>
-+#include <linux/list.h>
-+#include <linux/skbuff.h>
-+#include <linux/netdevice.h>
-+#include <linux/etherdevice.h>
-+#include <linux/rtnetlink.h>
-+#include <linux/if_arp.h>
-+#include <linux/netfilter.h>
-+#include <linux/netfilter_ipv4.h>
-+#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
-+	#include <linux/netfilter_ipv6.h>
-+#endif
-+#include <linux/imq.h>
-+#include <net/pkt_sched.h>
-+#include <net/netfilter/nf_queue.h>
++	  More information at: http://www.linuximq.net/
 +
-+static nf_hookfn imq_nf_hook;
++	  To compile this driver as a module, choose M here: the module
++	  will be called imq.  If unsure, say N.
 +
-+static struct nf_hook_ops imq_ingress_ipv4 = {
-+	.hook		= imq_nf_hook,
-+	.owner		= THIS_MODULE,
-+	.pf		= PF_INET,
-+	.hooknum	= NF_INET_PRE_ROUTING,
-+#if defined(CONFIG_IMQ_BEHAVIOR_BA) || defined(CONFIG_IMQ_BEHAVIOR_BB)
-+	.priority	= NF_IP_PRI_MANGLE + 1
-+#else
-+	.priority	= NF_IP_PRI_NAT_DST + 1
-+#endif
-+};
++choice
++	prompt "IMQ behavior (PRE/POSTROUTING)"
++	depends on IMQ
++	default IMQ_BEHAVIOR_AB
++	help
 +
-+static struct nf_hook_ops imq_egress_ipv4 = {
-+	.hook		= imq_nf_hook,
-+	.owner		= THIS_MODULE,
-+	.pf		= PF_INET,
-+	.hooknum	= NF_INET_POST_ROUTING,
-+#if defined(CONFIG_IMQ_BEHAVIOR_AA) || defined(CONFIG_IMQ_BEHAVIOR_BA)
-+	.priority	= NF_IP_PRI_LAST
-+#else
-+	.priority	= NF_IP_PRI_NAT_SRC - 1
-+#endif
-+};
++		This settings defines how IMQ behaves in respect to its
++		hooking in PREROUTING and POSTROUTING.
 +
-+#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
-+static struct nf_hook_ops imq_ingress_ipv6 = {
-+	.hook		= imq_nf_hook,
-+	.owner		= THIS_MODULE,
-+	.pf		= PF_INET6,
-+	.hooknum	= NF_INET_PRE_ROUTING,
-+#if defined(CONFIG_IMQ_BEHAVIOR_BA) || defined(CONFIG_IMQ_BEHAVIOR_BB)
-+	.priority	= NF_IP6_PRI_MANGLE + 1
-+#else
-+	.priority	= NF_IP6_PRI_NAT_DST + 1
-+#endif
-+};
++		IMQ can work in any of the following ways:
 +
-+static struct nf_hook_ops imq_egress_ipv6 = {
-+	.hook		= imq_nf_hook,
-+	.owner		= THIS_MODULE,
-+	.pf		= PF_INET6,
-+	.hooknum	= NF_INET_POST_ROUTING,
-+#if defined(CONFIG_IMQ_BEHAVIOR_AA) || defined(CONFIG_IMQ_BEHAVIOR_BA)
-+	.priority	= NF_IP6_PRI_LAST
-+#else
-+	.priority	= NF_IP6_PRI_NAT_SRC - 1
-+#endif
-+};
-+#endif
++		    PREROUTING   |      POSTROUTING
++		-----------------|-------------------
++		#1  After NAT    |      After NAT
++		#2  After NAT    |      Before NAT
++		#3  Before NAT   |      After NAT
++		#4  Before NAT   |      Before NAT
 +
-+#if defined(CONFIG_IMQ_NUM_DEVS)
-+static unsigned int numdevs = CONFIG_IMQ_NUM_DEVS;
-+#else
-+static unsigned int numdevs = IMQ_MAX_DEVS;
-+#endif
++		The default behavior is to hook before NAT on PREROUTING
++		and after NAT on POSTROUTING (#3).
 +
-+static DEFINE_SPINLOCK(imq_nf_queue_lock);
++		This settings are specially usefull when trying to use IMQ
++		to shape NATed clients.
 +
-+static struct net_device *imq_devs_cache[IMQ_MAX_DEVS];
++		More information can be found at: www.linuximq.net
 +
++		If not sure leave the default settings alone.
 +
-+static struct net_device_stats *imq_get_stats(struct net_device *dev)
-+{
-+	return &dev->stats;
-+}
++config IMQ_BEHAVIOR_AA
++	bool "IMQ AA"
++	help
++		This settings defines how IMQ behaves in respect to its
++		hooking in PREROUTING and POSTROUTING.
 +
-+/* called for packets kfree'd in qdiscs at places other than enqueue */
-+static void imq_skb_destructor(struct sk_buff *skb)
-+{
-+	struct nf_queue_entry *entry = skb->nf_queue_entry;
++		Choosing this option will make IMQ hook like this:
 +
-+	skb->nf_queue_entry = NULL;
++		PREROUTING:   After NAT
++		POSTROUTING:  After NAT
 +
-+	if (entry) {
-+		nf_queue_entry_release_refs(entry);
-+		kfree(entry);
-+	}
++		More information can be found at: www.linuximq.net
 +
-+	skb_restore_cb(skb); /* kfree backup */
-+}
++		If not sure leave the default settings alone.
 +
-+/* locking not needed when called from imq_nf_queue */
-+static void imq_nf_reinject_lockless(struct nf_queue_entry *entry,
-+						unsigned int verdict)
-+{
-+	int status;
++config IMQ_BEHAVIOR_AB
++	bool "IMQ AB"
++	help
++		This settings defines how IMQ behaves in respect to its
++		hooking in PREROUTING and POSTROUTING.
 +
-+	if (!entry->next_outfn) {
-+		nf_reinject(entry, verdict);
-+		return;
-+	}
++		Choosing this option will make IMQ hook like this:
 +
-+	status = entry->next_outfn(entry, entry->next_queuenum);
-+	if (status < 0) {
-+		nf_queue_entry_release_refs(entry);
-+		kfree_skb(entry->skb);
-+		kfree(entry);
-+	}
-+}
++		PREROUTING:   After NAT
++		POSTROUTING:  Before NAT
 +
-+static void imq_nf_reinject(struct nf_queue_entry *entry, unsigned int verdict)
-+{
-+	int status;
++		More information can be found at: www.linuximq.net
 +
-+	if (!entry->next_outfn) {
-+		spin_lock_bh(&imq_nf_queue_lock);
-+		nf_reinject(entry, verdict);
-+		spin_unlock_bh(&imq_nf_queue_lock);
-+		return;
-+	}
++		If not sure leave the default settings alone.
 +
-+	rcu_read_lock();
-+	local_bh_disable();
-+	status = entry->next_outfn(entry, entry->next_queuenum);
-+	local_bh_enable();
-+	if (status < 0) {
-+		nf_queue_entry_release_refs(entry);
-+		kfree_skb(entry->skb);
-+		kfree(entry);
-+	}
++config IMQ_BEHAVIOR_BA
++	bool "IMQ BA"
++	help
++		This settings defines how IMQ behaves in respect to its
++		hooking in PREROUTING and POSTROUTING.
 +
-+	rcu_read_unlock();
-+}
++		Choosing this option will make IMQ hook like this:
 +
-+static netdev_tx_t imq_dev_xmit(struct sk_buff *skb, struct net_device *dev)
-+{
-+	struct nf_queue_entry *entry = skb->nf_queue_entry;
++		PREROUTING:   Before NAT
++		POSTROUTING:  After NAT
 +
-+	skb->nf_queue_entry = NULL;
-+	dev->trans_start = jiffies;
++		More information can be found at: www.linuximq.net
 +
-+	dev->stats.tx_bytes += skb->len;
-+	dev->stats.tx_packets++;
-+
-+	if (entry == NULL) {
-+		/* We don't know what is going on here.. packet is queued for
-+		 * imq device, but (probably) not by us.
-+		 *
-+		 * If this packet was not send here by imq_nf_queue(), then
-+		 * skb_save_cb() was not used and skb_free() should not show:
-+		 *   WARNING: IMQ: kfree_skb: skb->cb_next:..
-+		 * and/or
-+		 *   WARNING: IMQ: kfree_skb: skb->nf_queue_entry...
-+		 *
-+		 * However if this message is shown, then IMQ is somehow broken
-+		 * and you should report this to linuximq.net.
-+		 */
++		If not sure leave the default settings alone.
 +
-+		/* imq_dev_xmit is black hole that eats all packets, report that
-+		 * we eat this packet happily and increase dropped counters.
-+		 */
++config IMQ_BEHAVIOR_BB
++	bool "IMQ BB"
++	help
++		This settings defines how IMQ behaves in respect to its
++		hooking in PREROUTING and POSTROUTING.
 +
-+		dev->stats.tx_dropped++;
-+		dev_kfree_skb(skb);
++		Choosing this option will make IMQ hook like this:
 +
-+		return NETDEV_TX_OK;
-+	}
++		PREROUTING:   Before NAT
++		POSTROUTING:  Before NAT
 +
-+	skb_restore_cb(skb); /* restore skb->cb */
++		More information can be found at: www.linuximq.net
 +
-+	skb->imq_flags = 0;
-+	skb->destructor = NULL;
++		If not sure leave the default settings alone.
 +
-+	imq_nf_reinject(entry, NF_ACCEPT);
++endchoice
 +
-+	return NETDEV_TX_OK;
-+}
++config IMQ_NUM_DEVS
 +
-+static int imq_nf_queue(struct nf_queue_entry *entry, unsigned queue_num)
-+{
-+	struct net_device *dev;
-+	struct sk_buff *skb_orig, *skb, *skb_shared;
-+	struct Qdisc *q;
-+	struct netdev_queue *txq;
-+	int users, index;
-+	int retval = -EINVAL;
++	int "Number of IMQ devices"
++	range 2 16
++	depends on IMQ
++	default "16"
++	help
 +
-+	index = entry->skb->imq_flags & IMQ_F_IFMASK;
-+	if (unlikely(index > numdevs - 1)) {
-+		if (net_ratelimit())
-+			printk(KERN_WARNING
-+			       "IMQ: invalid device specified, highest is %u\n",
-+			       numdevs - 1);
-+		retval = -EINVAL;
-+		goto out;
-+	}
++		This settings defines how many IMQ devices will be
++		created.
 +
-+	/* check for imq device by index from cache */
-+	dev = imq_devs_cache[index];
-+	if (unlikely(!dev)) {
-+		char buf[8];
++		The default value is 16.
 +
-+		/* get device by name and cache result */
-+		snprintf(buf, sizeof(buf), "imq%d", index);
-+		dev = dev_get_by_name(&init_net, buf);
-+		if (!dev) {
-+			/* not found ?!*/
-+			BUG();
-+			retval = -ENODEV;
-+			goto out;
-+		}
++		More information can be found at: www.linuximq.net
 +
-+		imq_devs_cache[index] = dev;
-+		dev_put(dev);
-+	}
++		If not sure leave the default settings alone.
 +
-+	if (unlikely(!(dev->flags & IFF_UP))) {
-+		entry->skb->imq_flags = 0;
-+		imq_nf_reinject_lockless(entry, NF_ACCEPT);
-+		retval = 0;
-+		goto out;
-+	}
-+	dev->last_rx = jiffies;
+ config TUN
+ 	tristate "Universal TUN/TAP device driver support"
+ 	select CRC32
+--- a/drivers/net/Makefile
++++ b/drivers/net/Makefile
+@@ -165,6 +165,7 @@ obj-$(CONFIG_SLHC) += slhc.o
+ obj-$(CONFIG_XEN_NETDEV_FRONTEND) += xen-netfront.o
+ 
+ obj-$(CONFIG_DUMMY) += dummy.o
++obj-$(CONFIG_IMQ) += imq.o
+ obj-$(CONFIG_IFB) += ifb.o
+ obj-$(CONFIG_MACVLAN) += macvlan.o
+ obj-$(CONFIG_DE600) += de600.o
+--- /dev/null
++++ b/include/linux/imq.h
+@@ -0,0 +1,13 @@
++#ifndef _IMQ_H
++#define _IMQ_H
 +
-+	skb = entry->skb;
-+	skb_orig = NULL;
++/* IFMASK (16 device indexes, 0 to 15) and flag(s) fit in 5 bits */
++#define IMQ_F_BITS	5
 +
-+	/* skb has owner? => make clone */
-+	if (unlikely(skb->destructor)) {
-+		skb_orig = skb;
-+		skb = skb_clone(skb, GFP_ATOMIC);
-+		if (!skb) {
-+			retval = -ENOMEM;
-+			goto out;
-+		}
-+		entry->skb = skb;
-+	}
++#define IMQ_F_IFMASK	0x0f
++#define IMQ_F_ENQUEUE	0x10
 +
-+	skb->nf_queue_entry = entry;
++#define IMQ_MAX_DEVS	(IMQ_F_IFMASK + 1)
 +
-+	dev->stats.rx_bytes += skb->len;
-+	dev->stats.rx_packets++;
++#endif /* _IMQ_H */
 +
-+	txq = dev_pick_tx(dev, skb);
+--- a/include/linux/netdevice.h
++++ b/include/linux/netdevice.h
+@@ -1114,6 +1114,7 @@ extern int		dev_alloc_name(struct net_de
+ extern int		dev_open(struct net_device *dev);
+ extern int		dev_close(struct net_device *dev);
+ extern void		dev_disable_lro(struct net_device *dev);
++extern struct netdev_queue *dev_pick_tx(struct net_device *dev, struct sk_buff *skb);
+ extern int		dev_queue_xmit(struct sk_buff *skb);
+ extern int		register_netdevice(struct net_device *dev);
+ extern void		unregister_netdevice(struct net_device *dev);
+--- /dev/null
++++ b/include/linux/netfilter/xt_IMQ.h
+@@ -0,0 +1,9 @@
++#ifndef _XT_IMQ_H
++#define _XT_IMQ_H
 +
-+	q = rcu_dereference(txq->qdisc);
-+	if (unlikely(!q->enqueue))
-+		goto packet_not_eaten_by_imq_dev;
++struct xt_imq_info {
++	unsigned int todev;     /* target imq device */
++};
 +
-+	spin_lock_bh(qdisc_lock(q));
++#endif /* _XT_IMQ_H */
 +
-+	users = atomic_read(&skb->users);
+--- /dev/null
++++ b/include/linux/netfilter_ipv4/ipt_IMQ.h
+@@ -0,0 +1,10 @@
++#ifndef _IPT_IMQ_H
++#define _IPT_IMQ_H
 +
-+	skb_shared = skb_get(skb); /* increase reference count by one */
-+	skb_save_cb(skb_shared); /* backup skb->cb, as qdisc layer will
-+					overwrite it */
-+	qdisc_enqueue_root(skb_shared, q); /* might kfree_skb */
++/* Backwards compatibility for old userspace */
++#include <linux/netfilter/xt_IMQ.h>
 +
-+	if (likely(atomic_read(&skb_shared->users) == users + 1)) {
-+		kfree_skb(skb_shared); /* decrease reference count by one */
++#define ipt_imq_info xt_imq_info
 +
-+		skb->destructor = &imq_skb_destructor;
++#endif /* _IPT_IMQ_H */
 +
-+		/* cloned? */
-+		if (skb_orig)
-+			kfree_skb(skb_orig); /* free original */
+--- /dev/null
++++ b/include/linux/netfilter_ipv6/ip6t_IMQ.h
+@@ -0,0 +1,10 @@
++#ifndef _IP6T_IMQ_H
++#define _IP6T_IMQ_H
 +
-+		spin_unlock_bh(qdisc_lock(q));
++/* Backwards compatibility for old userspace */
++#include <linux/netfilter/xt_IMQ.h>
 +
-+		/* schedule qdisc dequeue */
-+		__netif_schedule(q);
++#define ip6t_imq_info xt_imq_info
 +
-+		retval = 0;
-+		goto out;
-+	} else {
-+		skb_restore_cb(skb_shared); /* restore skb->cb */
-+		skb->nf_queue_entry = NULL;
-+		/* qdisc dropped packet and decreased skb reference count of
-+		 * skb, so we don't really want to and try refree as that would
-+		 * actually destroy the skb. */
-+		spin_unlock_bh(qdisc_lock(q));
-+		goto packet_not_eaten_by_imq_dev;
-+	}
++#endif /* _IP6T_IMQ_H */
 +
-+packet_not_eaten_by_imq_dev:
-+	/* cloned? restore original */
-+	if (skb_orig) {
-+		kfree_skb(skb);
-+		entry->skb = skb_orig;
-+	}
-+	retval = -1;
-+out:
-+	return retval;
-+}
+--- a/include/linux/skbuff.h
++++ b/include/linux/skbuff.h
+@@ -29,6 +29,9 @@
+ #include <linux/rcupdate.h>
+ #include <linux/dmaengine.h>
+ #include <linux/hrtimer.h>
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++#include <linux/imq.h>
++#endif
+ 
+ /* Don't change this without changing skb_csum_unnecessary! */
+ #define CHECKSUM_NONE 0
+@@ -330,6 +333,9 @@ struct sk_buff {
+ 	 * first. This is owned by whoever has the skb queued ATM.
+ 	 */
+ 	char			cb[48];
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++	void			*cb_next;
++#endif
+ 
+ 	unsigned int		len,
+ 				data_len;
+@@ -362,6 +368,9 @@ struct sk_buff {
+ 	struct nf_conntrack	*nfct;
+ 	struct sk_buff		*nfct_reasm;
+ #endif
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++	struct nf_queue_entry	*nf_queue_entry;
++#endif
+ #ifdef CONFIG_BRIDGE_NETFILTER
+ 	struct nf_bridge_info	*nf_bridge;
+ #endif
+@@ -383,6 +392,10 @@ struct sk_buff {
+ 
+ 	/* 0/14 bit hole */
+ 
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++	__u8			imq_flags:IMQ_F_BITS;
++#endif
 +
-+static struct nf_queue_handler nfqh = {
-+	.name  = "imq",
-+	.outfn = imq_nf_queue,
-+};
+ #ifdef CONFIG_NET_DMA
+ 	dma_cookie_t		dma_cookie;
+ #endif
+@@ -437,6 +450,12 @@ static inline struct rtable *skb_rtable(
+ 	return (struct rtable *)skb_dst(skb);
+ }
+ 
 +
-+static unsigned int imq_nf_hook(unsigned int hook, struct sk_buff *pskb,
-+				const struct net_device *indev,
-+				const struct net_device *outdev,
-+				int (*okfn)(struct sk_buff *))
-+{
-+	if (pskb->imq_flags & IMQ_F_ENQUEUE)
-+		return NF_QUEUE;
-+
-+	return NF_ACCEPT;
-+}
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++extern int skb_save_cb(struct sk_buff *skb);
++extern int skb_restore_cb(struct sk_buff *skb);
++#endif
 +
-+static int imq_close(struct net_device *dev)
-+{
-+	netif_stop_queue(dev);
-+	return 0;
-+}
+ extern void kfree_skb(struct sk_buff *skb);
+ extern void consume_skb(struct sk_buff *skb);
+ extern void	       __kfree_skb(struct sk_buff *skb);
+@@ -1972,6 +1991,10 @@ static inline void __nf_copy(struct sk_b
+ 	dst->nfct_reasm = src->nfct_reasm;
+ 	nf_conntrack_get_reasm(src->nfct_reasm);
+ #endif
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++	dst->imq_flags = src->imq_flags;
++	dst->nf_queue_entry = src->nf_queue_entry;
++#endif
+ #ifdef CONFIG_BRIDGE_NETFILTER
+ 	dst->nf_bridge  = src->nf_bridge;
+ 	nf_bridge_get(src->nf_bridge);
+--- a/include/net/netfilter/nf_queue.h
++++ b/include/net/netfilter/nf_queue.h
+@@ -13,6 +13,12 @@ struct nf_queue_entry {
+ 	struct net_device	*indev;
+ 	struct net_device	*outdev;
+ 	int			(*okfn)(struct sk_buff *);
 +
-+static int imq_open(struct net_device *dev)
-+{
-+	netif_start_queue(dev);
-+	return 0;
-+}
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++	int			(*next_outfn)(struct nf_queue_entry *entry,
++					      unsigned int queuenum);
++	unsigned int		next_queuenum;
++#endif
+ };
+ 
+ #define nf_queue_entry_reroute(x) ((void *)x + sizeof(struct nf_queue_entry))
+@@ -30,5 +36,11 @@ extern int nf_unregister_queue_handler(u
+ 				       const struct nf_queue_handler *qh);
+ extern void nf_unregister_queue_handlers(const struct nf_queue_handler *qh);
+ extern void nf_reinject(struct nf_queue_entry *entry, unsigned int verdict);
++extern void nf_queue_entry_release_refs(struct nf_queue_entry *entry);
 +
-+static const struct net_device_ops imq_netdev_ops = {
-+	.ndo_open		= imq_open,
-+	.ndo_stop		= imq_close,
-+	.ndo_start_xmit		= imq_dev_xmit,
-+	.ndo_get_stats		= imq_get_stats,
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++extern void nf_register_queue_imq_handler(const struct nf_queue_handler *qh);
++extern void nf_unregister_queue_imq_handler(void);
++#endif
+ 
+ #endif /* _NF_QUEUE_H */
+--- a/net/core/dev.c
++++ b/net/core/dev.c
+@@ -96,6 +96,9 @@
+ #include <net/net_namespace.h>
+ #include <net/sock.h>
+ #include <linux/rtnetlink.h>
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++#include <linux/imq.h>
++#endif
+ #include <linux/proc_fs.h>
+ #include <linux/seq_file.h>
+ #include <linux/stat.h>
+@@ -1704,7 +1707,11 @@ int dev_hard_start_xmit(struct sk_buff *
+ 	int rc;
+ 
+ 	if (likely(!skb->next)) {
+-		if (!list_empty(&ptype_all))
++		if (!list_empty(&ptype_all)
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++		    && !(skb->imq_flags & IMQ_F_ENQUEUE)
++#endif
++		    )
+ 			dev_queue_xmit_nit(skb, dev);
+ 
+ 		if (netif_needs_gso(dev, skb)) {
+@@ -1789,8 +1796,7 @@ u16 skb_tx_hash(const struct net_device
+ }
+ EXPORT_SYMBOL(skb_tx_hash);
+ 
+-static struct netdev_queue *dev_pick_tx(struct net_device *dev,
+-					struct sk_buff *skb)
++struct netdev_queue *dev_pick_tx(struct net_device *dev, struct sk_buff *skb)
+ {
+ 	const struct net_device_ops *ops = dev->netdev_ops;
+ 	u16 queue_index = 0;
+@@ -1803,6 +1809,7 @@ static struct netdev_queue *dev_pick_tx(
+ 	skb_set_queue_mapping(skb, queue_index);
+ 	return netdev_get_tx_queue(dev, queue_index);
+ }
++EXPORT_SYMBOL(dev_pick_tx);
+ 
+ static inline int __dev_xmit_skb(struct sk_buff *skb, struct Qdisc *q,
+ 				 struct net_device *dev,
+--- a/net/core/skbuff.c
++++ b/net/core/skbuff.c
+@@ -72,6 +72,9 @@
+ 
+ static struct kmem_cache *skbuff_head_cache __read_mostly;
+ static struct kmem_cache *skbuff_fclone_cache __read_mostly;
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++static struct kmem_cache *skbuff_cb_store_cache __read_mostly;
++#endif
+ 
+ static void sock_pipe_buf_release(struct pipe_inode_info *pipe,
+ 				  struct pipe_buffer *buf)
+@@ -91,6 +94,83 @@ static int sock_pipe_buf_steal(struct pi
+ 	return 1;
+ }
+ 
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++/* Control buffer save/restore for IMQ devices */
++struct skb_cb_table {
++	void			*cb_next;
++	atomic_t		refcnt;
++	char      		cb[48];
 +};
 +
-+static void imq_setup(struct net_device *dev)
-+{
-+	dev->netdev_ops		= &imq_netdev_ops;
-+	dev->type               = ARPHRD_VOID;
-+	dev->mtu                = 16000;
-+	dev->tx_queue_len       = 11000;
-+	dev->flags              = IFF_NOARP;
-+	dev->features           = NETIF_F_SG | NETIF_F_FRAGLIST |
-+				  NETIF_F_GSO | NETIF_F_HW_CSUM |
-+				  NETIF_F_HIGHDMA;
-+	dev->priv_flags		&= ~IFF_XMIT_DST_RELEASE;
-+}
++static DEFINE_SPINLOCK(skb_cb_store_lock);
 +
-+static int imq_validate(struct nlattr *tb[], struct nlattr *data[])
++int skb_save_cb(struct sk_buff *skb)
 +{
-+	int ret = 0;
-+
-+	if (tb[IFLA_ADDRESS]) {
-+		if (nla_len(tb[IFLA_ADDRESS]) != ETH_ALEN) {
-+			ret = -EINVAL;
-+			goto end;
-+		}
-+		if (!is_valid_ether_addr(nla_data(tb[IFLA_ADDRESS]))) {
-+			ret = -EADDRNOTAVAIL;
-+			goto end;
-+		}
-+	}
-+	return 0;
-+end:
-+	printk(KERN_WARNING "IMQ: imq_validate failed (%d)\n", ret);
-+	return ret;
-+}
-+
-+static struct rtnl_link_ops imq_link_ops __read_mostly = {
-+	.kind		= "imq",
-+	.priv_size	= 0,
-+	.setup		= imq_setup,
-+	.validate	= imq_validate,
-+};
++	struct skb_cb_table *next;
 +
-+static int __init imq_init_hooks(void)
-+{
-+	int err;
++	next = kmem_cache_alloc(skbuff_cb_store_cache, GFP_ATOMIC);
++	if (!next)
++		return -ENOMEM;
 +
-+	nf_register_queue_imq_handler(&nfqh);
++	BUILD_BUG_ON(sizeof(skb->cb) != sizeof(next->cb));
 +
-+	err = nf_register_hook(&imq_ingress_ipv4);
-+	if (err)
-+		goto err1;
-+
-+	err = nf_register_hook(&imq_egress_ipv4);
-+	if (err)
-+		goto err2;
++	memcpy(next->cb, skb->cb, sizeof(skb->cb));
++	next->cb_next = skb->cb_next;
 +
-+#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
-+	err = nf_register_hook(&imq_ingress_ipv6);
-+	if (err)
-+		goto err3;
-+
-+	err = nf_register_hook(&imq_egress_ipv6);
-+	if (err)
-+		goto err4;
-+#endif
++	atomic_set(&next->refcnt, 1);
 +
++	skb->cb_next = next;
 +	return 0;
-+
-+#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
-+err4:
-+	nf_unregister_hook(&imq_ingress_ipv6);
-+err3:
-+	nf_unregister_hook(&imq_egress_ipv4);
-+#endif
-+err2:
-+	nf_unregister_hook(&imq_ingress_ipv4);
-+err1:
-+	nf_unregister_queue_imq_handler();
-+	return err;
 +}
++EXPORT_SYMBOL(skb_save_cb);
 +
-+static int __init imq_init_one(int index)
++int skb_restore_cb(struct sk_buff *skb)
 +{
-+	struct net_device *dev;
-+	int ret;
++	struct skb_cb_table *next;
 +
-+	dev = alloc_netdev(0, "imq%d", imq_setup);
-+	if (!dev)
-+		return -ENOMEM;
++	if (!skb->cb_next)
++		return 0;
 +
-+	ret = dev_alloc_name(dev, dev->name);
-+	if (ret < 0)
-+		goto fail;
++	next = skb->cb_next;
 +
-+	dev->rtnl_link_ops = &imq_link_ops;
-+	ret = register_netdevice(dev);
-+	if (ret < 0)
-+		goto fail;
++	BUILD_BUG_ON(sizeof(skb->cb) != sizeof(next->cb));
++
++	memcpy(skb->cb, next->cb, sizeof(skb->cb));
++	skb->cb_next = next->cb_next;
++
++	spin_lock(&skb_cb_store_lock);
++
++	if (atomic_dec_and_test(&next->refcnt)) {
++		kmem_cache_free(skbuff_cb_store_cache, next);
++	}
++
++	spin_unlock(&skb_cb_store_lock);
 +
 +	return 0;
-+fail:
-+	free_netdev(dev);
-+	return ret;
 +}
++EXPORT_SYMBOL(skb_restore_cb);
 +
-+static int __init imq_init_devs(void)
++static void skb_copy_stored_cb(struct sk_buff *new, const struct sk_buff *__old)
 +{
-+	int err, i;
++	struct skb_cb_table *next;
++	struct sk_buff *old;
 +
-+	if (numdevs < 1 || numdevs > IMQ_MAX_DEVS) {
-+		printk(KERN_ERR "IMQ: numdevs has to be betweed 1 and %u\n",
-+		       IMQ_MAX_DEVS);
-+		return -EINVAL;
++	if (!__old->cb_next) {
++		new->cb_next = NULL;
++		return;
 +	}
 +
-+	rtnl_lock();
-+	err = __rtnl_link_register(&imq_link_ops);
++	spin_lock(&skb_cb_store_lock);
 +
-+	for (i = 0; i < numdevs && !err; i++)
-+		err = imq_init_one(i);
++	old = (struct sk_buff *)__old;
 +
-+	if (err) {
-+		__rtnl_link_unregister(&imq_link_ops);
-+		memset(imq_devs_cache, 0, sizeof(imq_devs_cache));
-+	}
-+	rtnl_unlock();
++	next = old->cb_next;
++	atomic_inc(&next->refcnt);
++	new->cb_next = next;
 +
-+	return err;
++	spin_unlock(&skb_cb_store_lock);
 +}
-+
-+static int __init imq_init_module(void)
-+{
-+	int err;
-+
-+#if defined(CONFIG_IMQ_NUM_DEVS)
-+	BUILD_BUG_ON(CONFIG_IMQ_NUM_DEVS > 16);
-+	BUILD_BUG_ON(CONFIG_IMQ_NUM_DEVS < 2);
-+	BUILD_BUG_ON(CONFIG_IMQ_NUM_DEVS - 1 > IMQ_F_IFMASK);
 +#endif
+ 
+ /* Pipe buffer operations for a socket. */
+ static struct pipe_buf_operations sock_pipe_buf_ops = {
+@@ -398,6 +478,26 @@ static void skb_release_head_state(struc
+ 		WARN_ON(in_irq());
+ 		skb->destructor(skb);
+ 	}
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++	/* This should not happen. When it does, avoid memleak by restoring
++	the chain of cb-backups. */
++	while(skb->cb_next != NULL) {
++		if (net_ratelimit())
++			printk(KERN_WARNING "IMQ: kfree_skb: skb->cb_next: "
++				"%08x\n", (unsigned int)skb->cb_next);
 +
-+	err = imq_init_devs();
-+	if (err) {
-+		printk(KERN_ERR "IMQ: Error trying imq_init_devs(net)\n");
-+		return err;
++		skb_restore_cb(skb);
 +	}
++	/* This should not happen either, nf_queue_entry is nullified in
++	 * imq_dev_xmit(). If we have non-NULL nf_queue_entry then we are
++	 * leaking entry pointers, maybe memory. We don't know if this is
++	 * pointer to already freed memory, or should this be freed.
++	 * If this happens we need to add refcounting, etc for nf_queue_entry.
++	 */
++	if (skb->nf_queue_entry && net_ratelimit())
++		printk(KERN_WARNING
++				"IMQ: kfree_skb: skb->nf_queue_entry != NULL");
++#endif
+ #if defined(CONFIG_NF_CONNTRACK) || defined(CONFIG_NF_CONNTRACK_MODULE)
+ 	nf_conntrack_put(skb->nfct);
+ 	nf_conntrack_put_reasm(skb->nfct_reasm);
+@@ -535,6 +635,9 @@ static void __copy_skb_header(struct sk_
+ 	new->sp			= secpath_get(old->sp);
+ #endif
+ 	memcpy(new->cb, old->cb, sizeof(old->cb));
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++	skb_copy_stored_cb(new, old);
++#endif
+ 	new->csum		= old->csum;
+ 	new->local_df		= old->local_df;
+ 	new->pkt_type		= old->pkt_type;
+@@ -2781,6 +2884,13 @@ void __init skb_init(void)
+ 						0,
+ 						SLAB_HWCACHE_ALIGN|SLAB_PANIC,
+ 						NULL);
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++	skbuff_cb_store_cache = kmem_cache_create("skbuff_cb_store_cache",
++						  sizeof(struct skb_cb_table),
++						  0,
++						  SLAB_HWCACHE_ALIGN|SLAB_PANIC,
++						  NULL);
++#endif
+ }
+ 
+ /**
+--- a/net/netfilter/Kconfig
++++ b/net/netfilter/Kconfig
+@@ -396,6 +396,18 @@ config NETFILTER_XT_TARGET_LED
+ 	  For more information on the LEDs available on your system, see
+ 	  Documentation/leds-class.txt
+ 
++config NETFILTER_XT_TARGET_IMQ
++        tristate '"IMQ" target support'
++	depends on NETFILTER_XTABLES
++	depends on IP_NF_MANGLE || IP6_NF_MANGLE
++	select IMQ
++	default m if NETFILTER_ADVANCED=n
++        help
++          This option adds a `IMQ' target which is used to specify if and
++          to which imq device packets should get enqueued/dequeued.
 +
-+	err = imq_init_hooks();
-+	if (err) {
-+		printk(KERN_ERR "IMQ: Error trying imq_init_hooks()\n");
-+		rtnl_link_unregister(&imq_link_ops);
-+		memset(imq_devs_cache, 0, sizeof(imq_devs_cache));
-+		return err;
-+	}
++          To compile it as a module, choose M here.  If unsure, say N.
 +
-+	printk(KERN_INFO "IMQ driver loaded successfully.\n");
+ config NETFILTER_XT_TARGET_MARK
+ 	tristate '"MARK" target support'
+ 	default m if NETFILTER_ADVANCED=n
+--- a/net/netfilter/Makefile
++++ b/net/netfilter/Makefile
+@@ -46,6 +46,7 @@ obj-$(CONFIG_NETFILTER_XT_TARGET_CONNMAR
+ obj-$(CONFIG_NETFILTER_XT_TARGET_CONNSECMARK) += xt_CONNSECMARK.o
+ obj-$(CONFIG_NETFILTER_XT_TARGET_DSCP) += xt_DSCP.o
+ obj-$(CONFIG_NETFILTER_XT_TARGET_HL) += xt_HL.o
++obj-$(CONFIG_NETFILTER_XT_TARGET_IMQ) += xt_IMQ.o
+ obj-$(CONFIG_NETFILTER_XT_TARGET_LED) += xt_LED.o
+ obj-$(CONFIG_NETFILTER_XT_TARGET_MARK) += xt_MARK.o
+ obj-$(CONFIG_NETFILTER_XT_TARGET_NFLOG) += xt_NFLOG.o
+--- a/net/netfilter/nf_queue.c
++++ b/net/netfilter/nf_queue.c
+@@ -20,6 +20,26 @@ static const struct nf_queue_handler *qu
+ 
+ static DEFINE_MUTEX(queue_handler_mutex);
+ 
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++static const struct nf_queue_handler *queue_imq_handler;
 +
-+#if defined(CONFIG_IMQ_BEHAVIOR_BA) || defined(CONFIG_IMQ_BEHAVIOR_BB)
-+	printk(KERN_INFO "\tHooking IMQ before NAT on PREROUTING.\n");
-+#else
-+	printk(KERN_INFO "\tHooking IMQ after NAT on PREROUTING.\n");
++void nf_register_queue_imq_handler(const struct nf_queue_handler *qh)
++{
++	mutex_lock(&queue_handler_mutex);
++	rcu_assign_pointer(queue_imq_handler, qh);
++	mutex_unlock(&queue_handler_mutex);
++}
++EXPORT_SYMBOL(nf_register_queue_imq_handler);
++
++void nf_unregister_queue_imq_handler(void)
++{
++	mutex_lock(&queue_handler_mutex);
++	rcu_assign_pointer(queue_imq_handler, NULL);
++	mutex_unlock(&queue_handler_mutex);
++}
++EXPORT_SYMBOL(nf_unregister_queue_imq_handler);
++#endif
++
+ /* return EBUSY when somebody else is registered, return EEXIST if the
+  * same handler is registered, return 0 in case of success. */
+ int nf_register_queue_handler(u_int8_t pf, const struct nf_queue_handler *qh)
+@@ -80,7 +100,7 @@ void nf_unregister_queue_handlers(const 
+ }
+ EXPORT_SYMBOL_GPL(nf_unregister_queue_handlers);
+ 
+-static void nf_queue_entry_release_refs(struct nf_queue_entry *entry)
++void nf_queue_entry_release_refs(struct nf_queue_entry *entry)
+ {
+ 	/* Release those devices we held, or Alexey will kill me. */
+ 	if (entry->indev)
+@@ -100,6 +120,7 @@ static void nf_queue_entry_release_refs(
+ 	/* Drop reference to owner of hook which queued us. */
+ 	module_put(entry->elem->owner);
+ }
++EXPORT_SYMBOL_GPL(nf_queue_entry_release_refs);
+ 
+ /*
+  * Any packet that leaves via this function must come back
+@@ -121,12 +142,26 @@ static int __nf_queue(struct sk_buff *sk
+ #endif
+ 	const struct nf_afinfo *afinfo;
+ 	const struct nf_queue_handler *qh;
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++	const struct nf_queue_handler *qih = NULL;
 +#endif
-+#if defined(CONFIG_IMQ_BEHAVIOR_AB) || defined(CONFIG_IMQ_BEHAVIOR_BB)
-+	printk(KERN_INFO "\tHooking IMQ before NAT on POSTROUTING.\n");
+ 
+ 	/* QUEUE == DROP if noone is waiting, to be safe. */
+ 	rcu_read_lock();
+ 
+ 	qh = rcu_dereference(queue_handler[pf]);
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
++	if (pf == PF_INET || pf == PF_INET6)
 +#else
-+	printk(KERN_INFO "\tHooking IMQ after NAT on POSTROUTING.\n");
++	if (pf == PF_INET)
 +#endif
++		qih = rcu_dereference(queue_imq_handler);
 +
-+	return 0;
-+}
++	if (!qh && !qih)
++#else /* !IMQ */
+ 	if (!qh)
++#endif
+ 		goto err_unlock;
+ 
+ 	afinfo = nf_get_afinfo(pf);
+@@ -145,6 +180,10 @@ static int __nf_queue(struct sk_buff *sk
+ 		.indev	= indev,
+ 		.outdev	= outdev,
+ 		.okfn	= okfn,
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++		.next_outfn = qh ? qh->outfn : NULL,
++		.next_queuenum = queuenum,
++#endif
+ 	};
+ 
+ 	/* If it's going away, ignore hook. */
+@@ -170,8 +209,19 @@ static int __nf_queue(struct sk_buff *sk
+ 	}
+ #endif
+ 	afinfo->saveroute(skb, entry);
 +
-+static void __exit imq_unhook(void)
-+{
-+#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
-+	nf_unregister_hook(&imq_ingress_ipv6);
-+	nf_unregister_hook(&imq_egress_ipv6);
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++	if (qih) {
++		status = qih->outfn(entry, queuenum);
++		goto imq_skip_queue;
++	}
 +#endif
-+	nf_unregister_hook(&imq_ingress_ipv4);
-+	nf_unregister_hook(&imq_egress_ipv4);
 +
-+	nf_unregister_queue_imq_handler();
-+}
+ 	status = qh->outfn(entry, queuenum);
+ 
++#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
++imq_skip_queue:
++#endif
+ 	rcu_read_unlock();
+ 
+ 	if (status < 0) {
+--- /dev/null
++++ b/net/netfilter/xt_IMQ.c
+@@ -0,0 +1,73 @@
++/*
++ * This target marks packets to be enqueued to an imq device
++ */
++#include <linux/module.h>
++#include <linux/skbuff.h>
++#include <linux/netfilter/x_tables.h>
++#include <linux/netfilter/xt_IMQ.h>
++#include <linux/imq.h>
 +
-+static void __exit imq_cleanup_devs(void)
++static unsigned int imq_target(struct sk_buff *pskb,
++				const struct xt_target_param *par)
 +{
-+	rtnl_link_unregister(&imq_link_ops);
-+	memset(imq_devs_cache, 0, sizeof(imq_devs_cache));
++	const struct xt_imq_info *mr = par->targinfo;
++
++	pskb->imq_flags = (mr->todev & IMQ_F_IFMASK) | IMQ_F_ENQUEUE;
++
++	return XT_CONTINUE;
 +}
 +
-+static void __exit imq_exit_module(void)
++static bool imq_checkentry(const struct xt_tgchk_param *par)
 +{
-+	imq_unhook();
-+	imq_cleanup_devs();
-+	printk(KERN_INFO "IMQ driver unloaded successfully.\n");
-+}
++	struct xt_imq_info *mr = par->targinfo;
 +
-+module_init(imq_init_module);
-+module_exit(imq_exit_module);
++	if (mr->todev > IMQ_MAX_DEVS - 1) {
++		printk(KERN_WARNING
++		       "IMQ: invalid device specified, highest is %u\n",
++		       IMQ_MAX_DEVS - 1);
++		return 0;
++	}
 +
-+module_param(numdevs, int, 0);
-+MODULE_PARM_DESC(numdevs, "number of IMQ devices (how many imq* devices will "
-+			"be created)");
-+MODULE_AUTHOR("http://www.linuximq.net");
-+MODULE_DESCRIPTION("Pseudo-driver for the intermediate queue device. See "
-+			"http://www.linuximq.net/ for more information.");
-+MODULE_LICENSE("GPL");
-+MODULE_ALIAS_RTNL_LINK("imq");
++	return 1;
++}
 +
---- a/drivers/net/Kconfig
-+++ b/drivers/net/Kconfig
-@@ -109,6 +109,129 @@ config EQUALIZER
- 	  To compile this driver as a module, choose M here: the module
- 	  will be called eql.  If unsure, say N.
- 
-+config IMQ
-+	tristate "IMQ (intermediate queueing device) support"
-+	depends on NETDEVICES && NETFILTER
-+	---help---
-+	  The IMQ device(s) is used as placeholder for QoS queueing
-+	  disciplines. Every packet entering/leaving the IP stack can be
-+	  directed through the IMQ device where it's enqueued/dequeued to the
-+	  attached qdisc. This allows you to treat network devices as classes
-+	  and distribute bandwidth among them. Iptables is used to specify
-+	  through which IMQ device, if any, packets travel.
++static struct xt_target xt_imq_reg[] __read_mostly = {
++	{
++		.name           = "IMQ",
++		.family		= AF_INET,
++		.checkentry     = imq_checkentry,
++		.target         = imq_target,
++		.targetsize	= sizeof(struct xt_imq_info),
++		.table		= "mangle",
++		.me             = THIS_MODULE
++	},
++	{
++		.name           = "IMQ",
++		.family		= AF_INET6,
++		.checkentry     = imq_checkentry,
++		.target         = imq_target,
++		.targetsize	= sizeof(struct xt_imq_info),
++		.table		= "mangle",
++		.me             = THIS_MODULE
++	},
++};
 +
-+	  More information at: http://www.linuximq.net/
++static int __init imq_init(void)
++{
++	return xt_register_targets(xt_imq_reg, ARRAY_SIZE(xt_imq_reg));
++}
 +
-+	  To compile this driver as a module, choose M here: the module
-+	  will be called imq.  If unsure, say N.
++static void __exit imq_fini(void)
++{
++	xt_unregister_targets(xt_imq_reg, ARRAY_SIZE(xt_imq_reg));
++}
 +
-+choice
-+	prompt "IMQ behavior (PRE/POSTROUTING)"
-+	depends on IMQ
-+	default IMQ_BEHAVIOR_AB
-+	help
++module_init(imq_init);
++module_exit(imq_fini);
 +
-+		This settings defines how IMQ behaves in respect to its
-+		hooking in PREROUTING and POSTROUTING.
++MODULE_AUTHOR("http://www.linuximq.net");
++MODULE_DESCRIPTION("Pseudo-driver for the intermediate queue device. See http://www.linuximq.net/ for more information.");
++MODULE_LICENSE("GPL");
++MODULE_ALIAS("ipt_IMQ");
++MODULE_ALIAS("ip6t_IMQ");
 +
-+		IMQ can work in any of the following ways:
+--- /dev/null	2010-05-13 10:11:58.394584532 -0400
++++ b/drivers/net/imq.c	2010-07-30 16:43:48.000000000 -0400
+@@ -0,0 +1,894 @@
++/*
++ *             Pseudo-driver for the intermediate queue device.
++ *
++ *             This program is free software; you can redistribute it and/or
++ *             modify it under the terms of the GNU General Public License
++ *             as published by the Free Software Foundation; either version
++ *             2 of the License, or (at your option) any later version.
++ *
++ * Authors:    Patrick McHardy, <kaber@trash.net>
++ *
++ *            The first version was written by Martin Devera, <devik@cdi.cz>
++ *
++ * Credits:    Jan Rafaj <imq2t@cedric.vabo.cz>
++ *              - Update patch to 2.4.21
++ *             Sebastian Strollo <sstrollo@nortelnetworks.com>
++ *              - Fix "Dead-loop on netdevice imq"-issue
++ *             Marcel Sebek <sebek64@post.cz>
++ *              - Update to 2.6.2-rc1
++ *
++ *	       After some time of inactivity there is a group taking care
++ *	       of IMQ again: http://www.linuximq.net
++ *
++ *
++ *	       2004/06/30 - New version of IMQ patch to kernels <=2.6.7
++ *             including the following changes:
++ *
++ *	       - Correction of ipv6 support "+"s issue (Hasso Tepper)
++ *	       - Correction of imq_init_devs() issue that resulted in
++ *	       kernel OOPS unloading IMQ as module (Norbert Buchmuller)
++ *	       - Addition of functionality to choose number of IMQ devices
++ *	       during kernel config (Andre Correa)
++ *	       - Addition of functionality to choose how IMQ hooks on
++ *	       PRE and POSTROUTING (after or before NAT) (Andre Correa)
++ *	       - Cosmetic corrections (Norbert Buchmuller) (Andre Correa)
++ *
++ *
++ *             2005/12/16 - IMQ versions between 2.6.7 and 2.6.13 were
++ *             released with almost no problems. 2.6.14-x was released
++ *             with some important changes: nfcache was removed; After
++ *             some weeks of trouble we figured out that some IMQ fields
++ *             in skb were missing in skbuff.c - skb_clone and copy_skb_header.
++ *             These functions are correctly patched by this new patch version.
++ *
++ *             Thanks for all who helped to figure out all the problems with
++ *             2.6.14.x: Patrick McHardy, Rune Kock, VeNoMouS, Max CtRiX,
++ *             Kevin Shanahan, Richard Lucassen, Valery Dachev (hopefully
++ *             I didn't forget anybody). I apologize again for my lack of time.
++ *
++ *
++ *             2008/06/17 - 2.6.25 - Changed imq.c to use qdisc_run() instead 
++ *             of qdisc_restart() and moved qdisc_run() to tasklet to avoid
++ *             recursive locking. New initialization routines to fix 'rmmod' not
++ *             working anymore. Used code from ifb.c. (Jussi Kivilinna)
++ *
++ *             2008/08/06 - 2.6.26 - (JK)
++ *              - Replaced tasklet with 'netif_schedule()'.
++ *              - Cleaned up and added comments for imq_nf_queue().
++ *
++ *             2009/04/12
++ *              - Add skb_save_cb/skb_restore_cb helper functions for backuping
++ *                control buffer. This is needed because qdisc-layer on kernels
++ *                2.6.27 and newer overwrite control buffer. (Jussi Kivilinna)
++ *              - Add better locking for IMQ device. Hopefully this will solve
++ *                SMP issues. (Jussi Kivilinna)
++ *              - Port to 2.6.27
++ *              - Port to 2.6.28
++ *              - Port to 2.6.29 + fix rmmod not working
++ *
++ *             2009/04/20 - (Jussi Kivilinna)
++ *              - Use netdevice feature flags to avoid extra packet handling
++ *                by core networking layer and possibly increase performance.
++ *
++ *             2009/09/26 - (Jussi Kivilinna)
++ *              - Add imq_nf_reinject_lockless to fix deadlock with
++ *                imq_nf_queue/imq_nf_reinject.
++ *
++ *             2009/12/08 - (Jussi Kivilinna)
++ *              - Port to 2.6.32
++ *              - Add check for skb->nf_queue_entry==NULL in imq_dev_xmit()
++ *              - Also add better error checking for skb->nf_queue_entry usage
++ *
++ *	       Also, many thanks to pablo Sebastian Greco for making the initial
++ *	       patch and to those who helped the testing.
++ *
++ *             More info at: http://www.linuximq.net/ (Andre Correa)
++ */
 +
-+		    PREROUTING   |      POSTROUTING
-+		-----------------|-------------------
-+		#1  After NAT    |      After NAT
-+		#2  After NAT    |      Before NAT
-+		#3  Before NAT   |      After NAT
-+		#4  Before NAT   |      Before NAT
++#include <linux/module.h>
++#include <linux/kernel.h>
++#include <linux/moduleparam.h>
++#include <linux/list.h>
++#include <linux/skbuff.h>
++#include <linux/netdevice.h>
++#include <linux/etherdevice.h>
++#include <linux/rtnetlink.h>
++#include <linux/if_arp.h>
++#include <linux/netfilter.h>
++#include <linux/netfilter_ipv4.h>
++#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
++	#include <linux/netfilter_ipv6.h>
++#endif
++#include <linux/imq.h>
++#include <net/pkt_sched.h>
++#include <net/netfilter/nf_queue.h>
 +
-+		The default behavior is to hook before NAT on PREROUTING
-+		and after NAT on POSTROUTING (#3).
++static nf_hookfn imq_nf_hook;
 +
-+		This settings are specially usefull when trying to use IMQ
-+		to shape NATed clients.
 +
-+		More information can be found at: www.linuximq.net
 +
-+		If not sure leave the default settings alone.
++#if defined(CONFIG_IMQ_NUM_DEVS)
++static unsigned int numdevs = CONFIG_IMQ_NUM_DEVS;
++#else
++static unsigned int numdevs = IMQ_MAX_DEVS;
++#endif
 +
-+config IMQ_BEHAVIOR_AA
-+	bool "IMQ AA"
-+	help
-+		This settings defines how IMQ behaves in respect to its
-+		hooking in PREROUTING and POSTROUTING.
++static DEFINE_SPINLOCK(imq_nf_queue_lock);
 +
-+		Choosing this option will make IMQ hook like this:
++static struct net_device *imq_devs_cache[IMQ_MAX_DEVS];
 +
-+		PREROUTING:   After NAT
-+		POSTROUTING:  After NAT
 +
-+		More information can be found at: www.linuximq.net
++static struct net_device_stats *imq_get_stats(struct net_device *dev)
++{
++	return &dev->stats;
++}
 +
-+		If not sure leave the default settings alone.
++/* called for packets kfree'd in qdiscs at places other than enqueue */
++static void imq_skb_destructor(struct sk_buff *skb)
++{
++	struct nf_queue_entry *entry = skb->nf_queue_entry;
 +
-+config IMQ_BEHAVIOR_AB
-+	bool "IMQ AB"
-+	help
-+		This settings defines how IMQ behaves in respect to its
-+		hooking in PREROUTING and POSTROUTING.
++	skb->nf_queue_entry = NULL;
 +
-+		Choosing this option will make IMQ hook like this:
++	if (entry) {
++		nf_queue_entry_release_refs(entry);
++		kfree(entry);
++	}
 +
-+		PREROUTING:   After NAT
-+		POSTROUTING:  Before NAT
++	skb_restore_cb(skb); /* kfree backup */
++}
 +
-+		More information can be found at: www.linuximq.net
++/* locking not needed when called from imq_nf_queue */
++static void imq_nf_reinject_lockless(struct nf_queue_entry *entry,
++						unsigned int verdict)
++{
++	int status;
 +
-+		If not sure leave the default settings alone.
++	if (!entry->next_outfn) {
++		nf_reinject(entry, verdict);
++		return;
++	}
 +
-+config IMQ_BEHAVIOR_BA
-+	bool "IMQ BA"
-+	help
-+		This settings defines how IMQ behaves in respect to its
-+		hooking in PREROUTING and POSTROUTING.
++	status = entry->next_outfn(entry, entry->next_queuenum);
++	if (status < 0) {
++		nf_queue_entry_release_refs(entry);
++		kfree_skb(entry->skb);
++		kfree(entry);
++	}
++}
 +
-+		Choosing this option will make IMQ hook like this:
++static void imq_nf_reinject(struct nf_queue_entry *entry, unsigned int verdict)
++{
++	int status;
 +
-+		PREROUTING:   Before NAT
-+		POSTROUTING:  After NAT
++	if (!entry->next_outfn) {
++		spin_lock_bh(&imq_nf_queue_lock);
++		nf_reinject(entry, verdict);
++		spin_unlock_bh(&imq_nf_queue_lock);
++		return;
++	}
 +
-+		More information can be found at: www.linuximq.net
++	rcu_read_lock();
++	local_bh_disable();
++	status = entry->next_outfn(entry, entry->next_queuenum);
++	local_bh_enable();
++	if (status < 0) {
++		nf_queue_entry_release_refs(entry);
++		kfree_skb(entry->skb);
++		kfree(entry);
++	}
 +
-+		If not sure leave the default settings alone.
-+
-+config IMQ_BEHAVIOR_BB
-+	bool "IMQ BB"
-+	help
-+		This settings defines how IMQ behaves in respect to its
-+		hooking in PREROUTING and POSTROUTING.
-+
-+		Choosing this option will make IMQ hook like this:
-+
-+		PREROUTING:   Before NAT
-+		POSTROUTING:  Before NAT
-+
-+		More information can be found at: www.linuximq.net
-+
-+		If not sure leave the default settings alone.
++	rcu_read_unlock();
++}
 +
-+endchoice
++static netdev_tx_t imq_dev_xmit(struct sk_buff *skb, struct net_device *dev)
++{
++	struct nf_queue_entry *entry = skb->nf_queue_entry;
 +
-+config IMQ_NUM_DEVS
++	skb->nf_queue_entry = NULL;
++	dev->trans_start = jiffies;
 +
-+	int "Number of IMQ devices"
-+	range 2 16
-+	depends on IMQ
-+	default "16"
-+	help
++	dev->stats.tx_bytes += skb->len;
++	dev->stats.tx_packets++;
 +
-+		This settings defines how many IMQ devices will be
-+		created.
++	if (entry == NULL) {
++		/* We don't know what is going on here.. packet is queued for
++		 * imq device, but (probably) not by us.
++		 *
++		 * If this packet was not send here by imq_nf_queue(), then
++		 * skb_save_cb() was not used and skb_free() should not show:
++		 *   WARNING: IMQ: kfree_skb: skb->cb_next:..
++		 * and/or
++		 *   WARNING: IMQ: kfree_skb: skb->nf_queue_entry...
++		 *
++		 * However if this message is shown, then IMQ is somehow broken
++		 * and you should report this to linuximq.net.
++		 */
 +
-+		The default value is 16.
++		/* imq_dev_xmit is black hole that eats all packets, report that
++		 * we eat this packet happily and increase dropped counters.
++		 */
 +
-+		More information can be found at: www.linuximq.net
++		dev->stats.tx_dropped++;
++		dev_kfree_skb(skb);
 +
-+		If not sure leave the default settings alone.
++		return NETDEV_TX_OK;
++	}
 +
- config TUN
- 	tristate "Universal TUN/TAP device driver support"
- 	select CRC32
---- a/drivers/net/Makefile
-+++ b/drivers/net/Makefile
-@@ -165,6 +165,7 @@ obj-$(CONFIG_SLHC) += slhc.o
- obj-$(CONFIG_XEN_NETDEV_FRONTEND) += xen-netfront.o
- 
- obj-$(CONFIG_DUMMY) += dummy.o
-+obj-$(CONFIG_IMQ) += imq.o
- obj-$(CONFIG_IFB) += ifb.o
- obj-$(CONFIG_MACVLAN) += macvlan.o
- obj-$(CONFIG_DE600) += de600.o
---- /dev/null
-+++ b/include/linux/imq.h
-@@ -0,0 +1,13 @@
-+#ifndef _IMQ_H
-+#define _IMQ_H
++	skb_restore_cb(skb); /* restore skb->cb */
 +
-+/* IFMASK (16 device indexes, 0 to 15) and flag(s) fit in 5 bits */
-+#define IMQ_F_BITS	5
++	skb->imq_flags = 0;
++	skb->destructor = NULL;
 +
-+#define IMQ_F_IFMASK	0x0f
-+#define IMQ_F_ENQUEUE	0x10
++	imq_nf_reinject(entry, NF_ACCEPT);
 +
-+#define IMQ_MAX_DEVS	(IMQ_F_IFMASK + 1)
++	return NETDEV_TX_OK;
++}
 +
-+#endif /* _IMQ_H */
++static int imq_nf_queue(struct nf_queue_entry *entry, unsigned queue_num)
++{
++	struct net_device *dev;
++	struct sk_buff *skb_orig, *skb, *skb_shared;
++	struct Qdisc *q;
++	struct netdev_queue *txq;
++	int users, index;
++	int retval = -EINVAL;
 +
---- a/include/linux/netdevice.h
-+++ b/include/linux/netdevice.h
-@@ -1114,6 +1114,7 @@ extern int		dev_alloc_name(struct net_de
- extern int		dev_open(struct net_device *dev);
- extern int		dev_close(struct net_device *dev);
- extern void		dev_disable_lro(struct net_device *dev);
-+extern struct netdev_queue *dev_pick_tx(struct net_device *dev, struct sk_buff *skb);
- extern int		dev_queue_xmit(struct sk_buff *skb);
- extern int		register_netdevice(struct net_device *dev);
- extern void		unregister_netdevice(struct net_device *dev);
---- /dev/null
-+++ b/include/linux/netfilter/xt_IMQ.h
-@@ -0,0 +1,9 @@
-+#ifndef _XT_IMQ_H
-+#define _XT_IMQ_H
++	index = entry->skb->imq_flags & IMQ_F_IFMASK;
++	if (unlikely(index > numdevs - 1)) {
++		if (net_ratelimit())
++			printk(KERN_WARNING
++			       "IMQ: invalid device specified, highest is %u\n",
++			       numdevs - 1);
++		retval = -EINVAL;
++		goto out;
++	}
 +
-+struct xt_imq_info {
-+	unsigned int todev;     /* target imq device */
-+};
++	/* check for imq device by index from cache */
++	dev = imq_devs_cache[index];
++	if (unlikely(!dev)) {
++		char buf[8];
 +
-+#endif /* _XT_IMQ_H */
++		/* get device by name and cache result */
++		snprintf(buf, sizeof(buf), "imq%d", index);
++		dev = dev_get_by_name(&init_net, buf);
++		if (!dev) {
++			/* not found ?!*/
++			BUG();
++			retval = -ENODEV;
++			goto out;
++		}
 +
---- /dev/null
-+++ b/include/linux/netfilter_ipv4/ipt_IMQ.h
-@@ -0,0 +1,10 @@
-+#ifndef _IPT_IMQ_H
-+#define _IPT_IMQ_H
++		imq_devs_cache[index] = dev;
++		dev_put(dev);
++	}
 +
-+/* Backwards compatibility for old userspace */
-+#include <linux/netfilter/xt_IMQ.h>
++	if (unlikely(!(dev->flags & IFF_UP))) {
++		entry->skb->imq_flags = 0;
++		imq_nf_reinject_lockless(entry, NF_ACCEPT);
++		retval = 0;
++		goto out;
++	}
++	dev->last_rx = jiffies;
 +
-+#define ipt_imq_info xt_imq_info
++	skb = entry->skb;
++	skb_orig = NULL;
 +
-+#endif /* _IPT_IMQ_H */
++	/* skb has owner? => make clone */
++	if (unlikely(skb->destructor)) {
++		skb_orig = skb;
++		skb = skb_clone(skb, GFP_ATOMIC);
++		if (!skb) {
++			retval = -ENOMEM;
++			goto out;
++		}
++		entry->skb = skb;
++	}
 +
---- /dev/null
-+++ b/include/linux/netfilter_ipv6/ip6t_IMQ.h
-@@ -0,0 +1,10 @@
-+#ifndef _IP6T_IMQ_H
-+#define _IP6T_IMQ_H
++	skb->nf_queue_entry = entry;
 +
-+/* Backwards compatibility for old userspace */
-+#include <linux/netfilter/xt_IMQ.h>
++	dev->stats.rx_bytes += skb->len;
++	dev->stats.rx_packets++;
 +
-+#define ip6t_imq_info xt_imq_info
++	txq = dev_pick_tx(dev, skb);
 +
-+#endif /* _IP6T_IMQ_H */
++	q = rcu_dereference(txq->qdisc);
++	if (unlikely(!q->enqueue))
++		goto packet_not_eaten_by_imq_dev;
 +
---- a/include/linux/skbuff.h
-+++ b/include/linux/skbuff.h
-@@ -29,6 +29,9 @@
- #include <linux/rcupdate.h>
- #include <linux/dmaengine.h>
- #include <linux/hrtimer.h>
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+#include <linux/imq.h>
-+#endif
- 
- /* Don't change this without changing skb_csum_unnecessary! */
- #define CHECKSUM_NONE 0
-@@ -330,6 +333,9 @@ struct sk_buff {
- 	 * first. This is owned by whoever has the skb queued ATM.
- 	 */
- 	char			cb[48];
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+	void			*cb_next;
-+#endif
- 
- 	unsigned int		len,
- 				data_len;
-@@ -362,6 +368,9 @@ struct sk_buff {
- 	struct nf_conntrack	*nfct;
- 	struct sk_buff		*nfct_reasm;
- #endif
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+	struct nf_queue_entry	*nf_queue_entry;
-+#endif
- #ifdef CONFIG_BRIDGE_NETFILTER
- 	struct nf_bridge_info	*nf_bridge;
- #endif
-@@ -383,6 +392,10 @@ struct sk_buff {
- 
- 	/* 0/14 bit hole */
- 
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+	__u8			imq_flags:IMQ_F_BITS;
-+#endif
++	spin_lock_bh(qdisc_lock(q));
 +
- #ifdef CONFIG_NET_DMA
- 	dma_cookie_t		dma_cookie;
- #endif
-@@ -437,6 +450,12 @@ static inline struct rtable *skb_rtable(
- 	return (struct rtable *)skb_dst(skb);
- }
- 
++	users = atomic_read(&skb->users);
 +
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+extern int skb_save_cb(struct sk_buff *skb);
-+extern int skb_restore_cb(struct sk_buff *skb);
-+#endif
++	skb_shared = skb_get(skb); /* increase reference count by one */
++	skb_save_cb(skb_shared); /* backup skb->cb, as qdisc layer will
++					overwrite it */
++	qdisc_enqueue_root(skb_shared, q); /* might kfree_skb */
 +
- extern void kfree_skb(struct sk_buff *skb);
- extern void consume_skb(struct sk_buff *skb);
- extern void	       __kfree_skb(struct sk_buff *skb);
-@@ -1972,6 +1991,10 @@ static inline void __nf_copy(struct sk_b
- 	dst->nfct_reasm = src->nfct_reasm;
- 	nf_conntrack_get_reasm(src->nfct_reasm);
- #endif
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+	dst->imq_flags = src->imq_flags;
-+	dst->nf_queue_entry = src->nf_queue_entry;
-+#endif
- #ifdef CONFIG_BRIDGE_NETFILTER
- 	dst->nf_bridge  = src->nf_bridge;
- 	nf_bridge_get(src->nf_bridge);
---- a/include/net/netfilter/nf_queue.h
-+++ b/include/net/netfilter/nf_queue.h
-@@ -13,6 +13,12 @@ struct nf_queue_entry {
- 	struct net_device	*indev;
- 	struct net_device	*outdev;
- 	int			(*okfn)(struct sk_buff *);
++	if (likely(atomic_read(&skb_shared->users) == users + 1)) {
++		kfree_skb(skb_shared); /* decrease reference count by one */
 +
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+	int			(*next_outfn)(struct nf_queue_entry *entry,
-+					      unsigned int queuenum);
-+	unsigned int		next_queuenum;
-+#endif
- };
- 
- #define nf_queue_entry_reroute(x) ((void *)x + sizeof(struct nf_queue_entry))
-@@ -30,5 +36,11 @@ extern int nf_unregister_queue_handler(u
- 				       const struct nf_queue_handler *qh);
- extern void nf_unregister_queue_handlers(const struct nf_queue_handler *qh);
- extern void nf_reinject(struct nf_queue_entry *entry, unsigned int verdict);
-+extern void nf_queue_entry_release_refs(struct nf_queue_entry *entry);
++		skb->destructor = &imq_skb_destructor;
 +
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+extern void nf_register_queue_imq_handler(const struct nf_queue_handler *qh);
-+extern void nf_unregister_queue_imq_handler(void);
-+#endif
- 
- #endif /* _NF_QUEUE_H */
---- a/net/core/dev.c
-+++ b/net/core/dev.c
-@@ -96,6 +96,9 @@
- #include <net/net_namespace.h>
- #include <net/sock.h>
- #include <linux/rtnetlink.h>
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+#include <linux/imq.h>
-+#endif
- #include <linux/proc_fs.h>
- #include <linux/seq_file.h>
- #include <linux/stat.h>
-@@ -1704,7 +1707,11 @@ int dev_hard_start_xmit(struct sk_buff *
- 	int rc;
- 
- 	if (likely(!skb->next)) {
--		if (!list_empty(&ptype_all))
-+		if (!list_empty(&ptype_all)
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+		    && !(skb->imq_flags & IMQ_F_ENQUEUE)
-+#endif
-+		    )
- 			dev_queue_xmit_nit(skb, dev);
- 
- 		if (netif_needs_gso(dev, skb)) {
-@@ -1789,8 +1796,7 @@ u16 skb_tx_hash(const struct net_device
- }
- EXPORT_SYMBOL(skb_tx_hash);
- 
--static struct netdev_queue *dev_pick_tx(struct net_device *dev,
--					struct sk_buff *skb)
-+struct netdev_queue *dev_pick_tx(struct net_device *dev, struct sk_buff *skb)
- {
- 	const struct net_device_ops *ops = dev->netdev_ops;
- 	u16 queue_index = 0;
-@@ -1803,6 +1809,7 @@ static struct netdev_queue *dev_pick_tx(
- 	skb_set_queue_mapping(skb, queue_index);
- 	return netdev_get_tx_queue(dev, queue_index);
- }
-+EXPORT_SYMBOL(dev_pick_tx);
- 
- static inline int __dev_xmit_skb(struct sk_buff *skb, struct Qdisc *q,
- 				 struct net_device *dev,
---- a/net/core/skbuff.c
-+++ b/net/core/skbuff.c
-@@ -72,6 +72,9 @@
- 
- static struct kmem_cache *skbuff_head_cache __read_mostly;
- static struct kmem_cache *skbuff_fclone_cache __read_mostly;
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+static struct kmem_cache *skbuff_cb_store_cache __read_mostly;
-+#endif
- 
- static void sock_pipe_buf_release(struct pipe_inode_info *pipe,
- 				  struct pipe_buffer *buf)
-@@ -91,6 +94,83 @@ static int sock_pipe_buf_steal(struct pi
- 	return 1;
- }
- 
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+/* Control buffer save/restore for IMQ devices */
-+struct skb_cb_table {
-+	void			*cb_next;
-+	atomic_t		refcnt;
-+	char      		cb[48];
-+};
++		/* cloned? */
++		if (skb_orig)
++			kfree_skb(skb_orig); /* free original */
 +
-+static DEFINE_SPINLOCK(skb_cb_store_lock);
++		spin_unlock_bh(qdisc_lock(q));
 +
-+int skb_save_cb(struct sk_buff *skb)
-+{
-+	struct skb_cb_table *next;
++		/* schedule qdisc dequeue */
++		__netif_schedule(q);
 +
-+	next = kmem_cache_alloc(skbuff_cb_store_cache, GFP_ATOMIC);
-+	if (!next)
-+		return -ENOMEM;
++		retval = 0;
++		goto out;
++	} else {
++		skb_restore_cb(skb_shared); /* restore skb->cb */
++		skb->nf_queue_entry = NULL;
++		/* qdisc dropped packet and decreased skb reference count of
++		 * skb, so we don't really want to and try refree as that would
++		 * actually destroy the skb. */
++		spin_unlock_bh(qdisc_lock(q));
++		goto packet_not_eaten_by_imq_dev;
++	}
 +
-+	BUILD_BUG_ON(sizeof(skb->cb) != sizeof(next->cb));
++packet_not_eaten_by_imq_dev:
++	/* cloned? restore original */
++	if (skb_orig) {
++		kfree_skb(skb);
++		entry->skb = skb_orig;
++	}
++	retval = -1;
++out:
++	return retval;
++}
 +
-+	memcpy(next->cb, skb->cb, sizeof(skb->cb));
-+	next->cb_next = skb->cb_next;
++static struct nf_queue_handler nfqh = {
++	.name  = "imq",
++	.outfn = imq_nf_queue,
++};
 +
-+	atomic_set(&next->refcnt, 1);
++static unsigned int imq_nf_hook(unsigned int hook, struct sk_buff *pskb,
++				const struct net_device *indev,
++				const struct net_device *outdev,
++				int (*okfn)(struct sk_buff *))
++{
++	if (pskb->imq_flags & IMQ_F_ENQUEUE)
++		return NF_QUEUE;
 +
-+	skb->cb_next = next;
++	return NF_ACCEPT;
++}
++
++static int imq_close(struct net_device *dev)
++{
++	netif_stop_queue(dev);
 +	return 0;
 +}
-+EXPORT_SYMBOL(skb_save_cb);
 +
-+int skb_restore_cb(struct sk_buff *skb)
++static int imq_open(struct net_device *dev)
 +{
-+	struct skb_cb_table *next;
++	netif_start_queue(dev);
++	return 0;
++}
 +
-+	if (!skb->cb_next)
-+		return 0;
++static const struct net_device_ops imq_netdev_ops = {
++	.ndo_open		= imq_open,
++	.ndo_stop		= imq_close,
++	.ndo_start_xmit		= imq_dev_xmit,
++	.ndo_get_stats		= imq_get_stats,
++};
 +
-+	next = skb->cb_next;
++static void imq_setup(struct net_device *dev)
++{
++	dev->netdev_ops		= &imq_netdev_ops;
++	dev->type               = ARPHRD_VOID;
++	dev->mtu                = 16000;
++	dev->tx_queue_len       = 11000;
++	dev->flags              = IFF_NOARP;
++	dev->features           = NETIF_F_SG | NETIF_F_FRAGLIST |
++				  NETIF_F_GSO | NETIF_F_HW_CSUM |
++				  NETIF_F_HIGHDMA;
++	dev->priv_flags		&= ~IFF_XMIT_DST_RELEASE;
++}
 +
-+	BUILD_BUG_ON(sizeof(skb->cb) != sizeof(next->cb));
++static int imq_validate(struct nlattr *tb[], struct nlattr *data[])
++{
++	int ret = 0;
 +
-+	memcpy(skb->cb, next->cb, sizeof(skb->cb));
-+	skb->cb_next = next->cb_next;
++	if (tb[IFLA_ADDRESS]) {
++		if (nla_len(tb[IFLA_ADDRESS]) != ETH_ALEN) {
++			ret = -EINVAL;
++			goto end;
++		}
++		if (!is_valid_ether_addr(nla_data(tb[IFLA_ADDRESS]))) {
++			ret = -EADDRNOTAVAIL;
++			goto end;
++		}
++	}
++	return 0;
++end:
++	printk(KERN_WARNING "IMQ: imq_validate failed (%d)\n", ret);
++	return ret;
++}
 +
-+	spin_lock(&skb_cb_store_lock);
++static struct rtnl_link_ops imq_link_ops __read_mostly = {
++	.kind		= "imq",
++	.priv_size	= 0,
++	.setup		= imq_setup,
++	.validate	= imq_validate,
++};
 +
-+	if (atomic_dec_and_test(&next->refcnt)) {
-+		kmem_cache_free(skbuff_cb_store_cache, next);
-+	}
 +
-+	spin_unlock(&skb_cb_store_lock);
 +
-+	return 0;
++static inline char *kernel_strdup(const char *str)
++{
++	char *tmp;
++	long int s;
++	s=strlen(str) + 1;
++	tmp = kmalloc(s, GFP_ATOMIC);
++	if (tmp != NULL)
++	{
++		memcpy(tmp, str, s);
++	}
++	return tmp;
 +}
-+EXPORT_SYMBOL(skb_restore_cb);
 +
-+static void skb_copy_stored_cb(struct sk_buff *new, const struct sk_buff *__old)
++/*
++ * line is the line to be parsed -- it is not modified in any way
++ * max_pieces indicates number of pieces to return, if negative this is determined dynamically
++ * include_remainder_at_max indicates whether the last piece, when max pieces are reached, 
++ * 	should be what it would normally be (0) or the entire remainder of the line (1)
++ * 	if max_pieces < 0 this parameter is ignored
++ *
++ *
++ * returns all non-separator pieces in a line
++ * result is dynamically allocated, MUST be freed after call-- even if 
++ * line is empty (you still get a valid char** pointer to to a NULL char*)
++ */
++char** split_on_separators(char* line, char* separators, int num_separators, int max_pieces, int include_remainder_at_max, unsigned long *num_pieces)
 +{
-+	struct skb_cb_table *next;
-+	struct sk_buff *old;
++	char** split;
++	
++	*num_pieces = 0;
++	if(line != NULL)
++	{
++		int split_index;
++		int non_separator_found;
++		char* dup_line;
++		char* start;
++
++		if(max_pieces < 0)
++		{
++			/* count number of separator characters in line -- this count + 1 is an upperbound on number of pieces */
++			int separator_count = 0;
++			int line_index;
++			for(line_index = 0; line[line_index] != '\0'; line_index++)
++			{
++				int sep_index;
++				int found = 0;
++				for(sep_index =0; found == 0 && sep_index < num_separators; sep_index++)
++				{
++					found = separators[sep_index] == line[line_index] ? 1 : 0;
++				}
++				separator_count = separator_count+ found;
++			}
++			max_pieces = separator_count + 1;
++		}
++		split = (char**)kmalloc((1+max_pieces)*sizeof(char*), GFP_ATOMIC);
++		split_index = 0;
++		split[split_index] = NULL;
++
++
++		dup_line = kernel_strdup(line);
++		start = dup_line;
++		non_separator_found = 0;
++		while(non_separator_found == 0)
++		{
++			int matches = 0;
++			int sep_index;
++			for(sep_index =0; sep_index < num_separators; sep_index++)
++			{
++				matches = matches == 1 || separators[sep_index] == start[0] ? 1 : 0;
++			}
++			non_separator_found = matches==0 || start[0] == '\0' ? 1 : 0;
++			if(non_separator_found == 0)
++			{
++				start++;
++			}
++		}
 +
-+	if (!__old->cb_next) {
-+		new->cb_next = NULL;
-+		return;
++		while(start[0] != '\0' && split_index < max_pieces)
++		{
++			/* find first separator index */
++			int first_separator_index = 0;
++			int separator_found = 0;
++			while(	separator_found == 0 )
++			{
++				int sep_index;
++				for(sep_index =0; separator_found == 0 && sep_index < num_separators; sep_index++)
++				{
++					separator_found = separators[sep_index] == start[first_separator_index] || start[first_separator_index] == '\0' ? 1 : 0;
++				}
++				if(separator_found == 0)
++				{
++					first_separator_index++;
++				}
++			}
++			
++			/* copy next piece to split array */
++			if(first_separator_index > 0)
++			{
++				char* next_piece = NULL;
++				if(split_index +1 < max_pieces || include_remainder_at_max <= 0)
++				{
++					next_piece = (char*)kmalloc((first_separator_index+1)*sizeof(char), GFP_ATOMIC);
++					memcpy(next_piece, start, first_separator_index);
++					next_piece[first_separator_index] = '\0';
++				}
++				else
++				{
++					next_piece = kernel_strdup(start);
++				}
++				split[split_index] = next_piece;
++				split[split_index+1] = NULL;
++				split_index++;
++			}
++
++
++			/* find next non-separator index, indicating start of next piece */
++			start = start+ first_separator_index;
++			non_separator_found = 0;
++			while(non_separator_found == 0)
++			{
++				int matches = 0;
++				int sep_index;
++				for(sep_index =0; sep_index < num_separators; sep_index++)
++				{
++					matches = matches == 1 || separators[sep_index] == start[0] ? 1 : 0;
++				}
++				non_separator_found = matches==0 || start[0] == '\0' ? 1 : 0;
++				if(non_separator_found == 0)
++				{
++					start++;
++				}
++			}
++		}
++		kfree(dup_line);
++		*num_pieces = split_index;
++	}
++	else
++	{
++		split = (char**)kmalloc((1)*sizeof(char*), GFP_ATOMIC);
++		split[0] = NULL;
 +	}
++	return split;
++}
 +
-+	spin_lock(&skb_cb_store_lock);
 +
-+	old = (struct sk_buff *)__old;
++/* returns number freed */
++int free_null_terminated_string_array(char** strs)
++{
++	unsigned long str_index = 0;
++	if(strs != NULL)
++	{
++		for(str_index=0; strs[str_index] != NULL; str_index++)
++		{
++			kfree(strs[str_index]);
++		}
++		kfree(strs);
++	}
++	return str_index;
++}
 +
-+	next = old->cb_next;
-+	atomic_inc(&next->refcnt);
-+	new->cb_next = next;
 +
-+	spin_unlock(&skb_cb_store_lock);
-+}
-+#endif
- 
- /* Pipe buffer operations for a socket. */
- static struct pipe_buf_operations sock_pipe_buf_ops = {
-@@ -398,6 +478,26 @@ static void skb_release_head_state(struc
- 		WARN_ON(in_irq());
- 		skb->destructor(skb);
- 	}
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+	/* This should not happen. When it does, avoid memleak by restoring
-+	the chain of cb-backups. */
-+	while(skb->cb_next != NULL) {
-+		if (net_ratelimit())
-+			printk(KERN_WARNING "IMQ: kfree_skb: skb->cb_next: "
-+				"%08x\n", (unsigned int)skb->cb_next);
 +
-+		skb_restore_cb(skb);
-+	}
-+	/* This should not happen either, nf_queue_entry is nullified in
-+	 * imq_dev_xmit(). If we have non-NULL nf_queue_entry then we are
-+	 * leaking entry pointers, maybe memory. We don't know if this is
-+	 * pointer to already freed memory, or should this be freed.
-+	 * If this happens we need to add refcounting, etc for nf_queue_entry.
-+	 */
-+	if (skb->nf_queue_entry && net_ratelimit())
-+		printk(KERN_WARNING
-+				"IMQ: kfree_skb: skb->nf_queue_entry != NULL");
-+#endif
- #if defined(CONFIG_NF_CONNTRACK) || defined(CONFIG_NF_CONNTRACK_MODULE)
- 	nf_conntrack_put(skb->nfct);
- 	nf_conntrack_put_reasm(skb->nfct_reasm);
-@@ -535,6 +635,9 @@ static void __copy_skb_header(struct sk_
- 	new->sp			= secpath_get(old->sp);
- #endif
- 	memcpy(new->cb, old->cb, sizeof(old->cb));
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+	skb_copy_stored_cb(new, old);
++#if defined(CONFIG_IMQ_BEHAVIOR_BA) || defined(CONFIG_IMQ_BEHAVIOR_BB)
++	#define DEFAULT_PRE_TABLE "mangle"
++#else
++	#define DEFAULT_PRE_TABLE "nat"
 +#endif
- 	new->csum		= old->csum;
- 	new->local_df		= old->local_df;
- 	new->pkt_type		= old->pkt_type;
-@@ -2781,6 +2884,13 @@ void __init skb_init(void)
- 						0,
- 						SLAB_HWCACHE_ALIGN|SLAB_PANIC,
- 						NULL);
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+	skbuff_cb_store_cache = kmem_cache_create("skbuff_cb_store_cache",
-+						  sizeof(struct skb_cb_table),
-+						  0,
-+						  SLAB_HWCACHE_ALIGN|SLAB_PANIC,
-+						  NULL);
++
++#if defined(CONFIG_IMQ_BEHAVIOR_AA) || defined(CONFIG_IMQ_BEHAVIOR_BA)
++	#define DEFAULT_POST_TABLE "nat"
++#else
++	#define DEFAULT_POST_TABLE "mangle"
 +#endif
- }
- 
- /**
---- a/net/netfilter/Kconfig
-+++ b/net/netfilter/Kconfig
-@@ -396,6 +396,18 @@ config NETFILTER_XT_TARGET_LED
- 	  For more information on the LEDs available on your system, see
- 	  Documentation/leds-class.txt
- 
-+config NETFILTER_XT_TARGET_IMQ
-+        tristate '"IMQ" target support'
-+	depends on NETFILTER_XTABLES
-+	depends on IP_NF_MANGLE || IP6_NF_MANGLE
-+	select IMQ
-+	default m if NETFILTER_ADVANCED=n
-+        help
-+          This option adds a `IMQ' target which is used to specify if and
-+          to which imq device packets should get enqueued/dequeued.
 +
-+          To compile it as a module, choose M here.  If unsure, say N.
 +
- config NETFILTER_XT_TARGET_MARK
- 	tristate '"MARK" target support'
- 	default m if NETFILTER_ADVANCED=n
---- a/net/netfilter/Makefile
-+++ b/net/netfilter/Makefile
-@@ -46,6 +46,7 @@ obj-$(CONFIG_NETFILTER_XT_TARGET_CONNMAR
- obj-$(CONFIG_NETFILTER_XT_TARGET_CONNSECMARK) += xt_CONNSECMARK.o
- obj-$(CONFIG_NETFILTER_XT_TARGET_DSCP) += xt_DSCP.o
- obj-$(CONFIG_NETFILTER_XT_TARGET_HL) += xt_HL.o
-+obj-$(CONFIG_NETFILTER_XT_TARGET_IMQ) += xt_IMQ.o
- obj-$(CONFIG_NETFILTER_XT_TARGET_LED) += xt_LED.o
- obj-$(CONFIG_NETFILTER_XT_TARGET_MARK) += xt_MARK.o
- obj-$(CONFIG_NETFILTER_XT_TARGET_NFLOG) += xt_NFLOG.o
---- a/net/netfilter/nf_queue.c
-+++ b/net/netfilter/nf_queue.c
-@@ -20,6 +20,26 @@ static const struct nf_queue_handler *qu
- 
- static DEFINE_MUTEX(queue_handler_mutex);
- 
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+static const struct nf_queue_handler *queue_imq_handler;
 +
-+void nf_register_queue_imq_handler(const struct nf_queue_handler *qh)
-+{
-+	mutex_lock(&queue_handler_mutex);
-+	rcu_assign_pointer(queue_imq_handler, qh);
-+	mutex_unlock(&queue_handler_mutex);
++static char* hook_chains = "PREROUTING,POSTROUTING";
++static char* hook_tables = DEFAULT_PRE_TABLE "," DEFAULT_POST_TABLE;
++
++static struct nf_hook_ops* hook_list = NULL;
++static int hook_list_length = 0;
++
++
++static int __init imq_init_hooks(void)
++{
++
++
++	char separators[4] = {',', ' ', '\t', '\0' };
++	unsigned long num_chains;
++	unsigned long num_tables;
++	char** chain_list = split_on_separators(hook_chains, separators, 3, -1, 0, &num_chains);
++	char** table_list = split_on_separators(hook_tables, separators, 3, -1, 0, &num_tables);
++	int hook_index = 0;
++	
++	nf_register_queue_imq_handler(&nfqh);
++
++
++	hook_list_length = 0;
++	if(num_chains != num_tables)
++	{
++		printk("ERROR: must have same number of chains and tables\n");
++		return -1;
++	}
++	
++	/* we multiply by 2 here since we need hooks for both IPv4 and IPv6 */
++	hook_list = (struct nf_hook_ops*)kmalloc(sizeof(struct nf_hook_ops)*((num_chains*2)+1), GFP_ATOMIC); 
++	
++	
++	for(hook_index=0; hook_index < num_chains; hook_index++)
++	{
++		char* chain = chain_list[hook_index];
++		char* table = table_list[hook_index];
++		int valid = 0;
++		if(strcmp(chain, "PREROUTING") == 0 || strcmp(chain, "POSTROUTING") == 0 || strcmp(chain, "INPUT") == 0 || strcmp(chain, "FORWARD") == 0 || strcmp(chain, "OUTPUT") == 0)
++		{
++			if( 	strcmp(table, "mangle") == 0 || 
++				(strcmp(table, "nat") == 0 && strcmp(chain, "FORWARD") != 0 && strcmp(chain, "INPUT") != 0 ) || 
++				(strcmp(table, "filter") == 0 && strcmp(chain, "PREROUTING") != 0 && strcmp(chain, "POSTROUTING") != 0 )
++			  )
++			{
++				unsigned int chain_id = NF_INET_PRE_ROUTING;
++				int table_id = NF_IP_PRI_MANGLE;
++				int err = 0;
++
++				valid = 1;
++
++				if(strcmp(chain, "PREROUTING") == 0)
++				{
++					chain_id = NF_INET_PRE_ROUTING;
++				}
++				else if (strcmp(chain, "POSTROUTING") == 0)
++				{
++					chain_id = NF_INET_POST_ROUTING;
++				}
++				else if (strcmp(chain, "INPUT") == 0)
++				{
++					chain_id = NF_INET_LOCAL_IN;
++
++				}
++				else if (strcmp(chain, "FORWARD") == 0)
++				{
++					chain_id = NF_INET_FORWARD;
++
++				}
++				else if (strcmp(chain, "OUTPUT") == 0)
++				{
++					chain_id = NF_INET_LOCAL_OUT;
++				}
++
++				if(strcmp(table, "mangle") == 0)
++				{
++					table_id = NF_IP_PRI_MANGLE+1;
++				}
++				else if (strcmp(table, "nat") == 0 && strcmp(chain, "POSTROUTING") == 0)
++				{
++					table_id = NF_IP_PRI_NAT_SRC+1;
++				}
++				else if (strcmp(table, "nat") == 0 && strcmp(chain, "POSTROUTING") != 0)
++				{
++					table_id = NF_IP_PRI_NAT_DST+1;
++				}
++				else if (strcmp(table, "filter") == 0)
++				{
++					table_id = NF_IP_PRI_FILTER+1;
++				}
++				(hook_list[hook_list_length]).hook = imq_nf_hook;
++				(hook_list[hook_list_length]).owner = THIS_MODULE;
++				(hook_list[hook_list_length]).pf = PF_INET;
++				(hook_list[hook_list_length]).hooknum = chain_id;
++				(hook_list[hook_list_length]).priority = table_id;
++				err = nf_register_hook( (hook_list + hook_list_length) );
++				hook_list_length++;
++
++				#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
++					if(strcmp(table, "mangle") == 0)
++					{
++						table_id = NF_IP6_PRI_MANGLE+1;
++					}
++					else if (strcmp(table, "nat") == 0 && strcmp(chain, "POSTROUTING") == 0)
++					{
++						table_id = NF_IP6_PRI_NAT_SRC+1;
++					}
++					else if (strcmp(table, "nat") == 0 && strcmp(chain, "POSTROUTING") != 0)
++					{
++						table_id = NF_IP6_PRI_NAT_DST+1;
++					}
++					else if (strcmp(table, "filter") == 0)
++					{
++						table_id = NF_IP6_PRI_FILTER+1;
++					}
++
++					(hook_list[hook_list_length]).hook = imq_nf_hook;
++					(hook_list[hook_list_length]).owner = THIS_MODULE;
++					(hook_list[hook_list_length]).pf = PF_INET6;
++					(hook_list[hook_list_length]).hooknum = chain_id;
++					(hook_list[hook_list_length]).priority = table_id;
++					nf_register_hook( (hook_list + hook_list_length) );
++					hook_list_length++;
++				#endif
++
++
++				if(err)
++				{
++					printk(KERN_INFO "\tError hooking IMQ after %s on %s\n", table, chain);
++				}
++				else
++				{
++					printk(KERN_INFO "\tHooked IMQ after %s on %s\n", table, chain);
++				}
++
++			}
++		}
++		if(valid == 0)
++		{
++			printk("ERROR: invalid chain/table at index %d (%s/%s)\n", hook_index, chain, table);
++		}
++	}
++	free_null_terminated_string_array(chain_list);
++	free_null_terminated_string_array(table_list);
++
++	return 0;
++
 +}
-+EXPORT_SYMBOL(nf_register_queue_imq_handler);
 +
-+void nf_unregister_queue_imq_handler(void)
++
++
++
++
++static void __exit imq_unhook(void)
 +{
-+	mutex_lock(&queue_handler_mutex);
-+	rcu_assign_pointer(queue_imq_handler, NULL);
-+	mutex_unlock(&queue_handler_mutex);
++
++	int hook_index = 0;
++	for(hook_index = 0; hook_index < hook_list_length; hook_index++)
++	{
++		nf_unregister_hook( (hook_list+hook_index) );
++	}
++	nf_unregister_queue_imq_handler();
++
++	kfree(hook_list);
++	hook_list_length = 0;
++
 +}
-+EXPORT_SYMBOL(nf_unregister_queue_imq_handler);
-+#endif
 +
- /* return EBUSY when somebody else is registered, return EEXIST if the
-  * same handler is registered, return 0 in case of success. */
- int nf_register_queue_handler(u_int8_t pf, const struct nf_queue_handler *qh)
-@@ -80,7 +100,7 @@ void nf_unregister_queue_handlers(const
- }
- EXPORT_SYMBOL_GPL(nf_unregister_queue_handlers);
- 
--static void nf_queue_entry_release_refs(struct nf_queue_entry *entry)
-+void nf_queue_entry_release_refs(struct nf_queue_entry *entry)
- {
- 	/* Release those devices we held, or Alexey will kill me. */
- 	if (entry->indev)
-@@ -100,6 +120,7 @@ static void nf_queue_entry_release_refs(
- 	/* Drop reference to owner of hook which queued us. */
- 	module_put(entry->elem->owner);
- }
-+EXPORT_SYMBOL_GPL(nf_queue_entry_release_refs);
- 
- /*
-  * Any packet that leaves via this function must come back
-@@ -121,12 +142,26 @@ static int __nf_queue(struct sk_buff *sk
- #endif
- 	const struct nf_afinfo *afinfo;
- 	const struct nf_queue_handler *qh;
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+	const struct nf_queue_handler *qih = NULL;
-+#endif
- 
- 	/* QUEUE == DROP if noone is waiting, to be safe. */
- 	rcu_read_lock();
- 
- 	qh = rcu_dereference(queue_handler[pf]);
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+#if defined(CONFIG_IPV6) || defined(CONFIG_IPV6_MODULE)
-+	if (pf == PF_INET || pf == PF_INET6)
-+#else
-+	if (pf == PF_INET)
-+#endif
-+		qih = rcu_dereference(queue_imq_handler);
 +
-+	if (!qh && !qih)
-+#else /* !IMQ */
- 	if (!qh)
-+#endif
- 		goto err_unlock;
- 
- 	afinfo = nf_get_afinfo(pf);
-@@ -145,6 +180,10 @@ static int __nf_queue(struct sk_buff *sk
- 		.indev	= indev,
- 		.outdev	= outdev,
- 		.okfn	= okfn,
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+		.next_outfn = qh ? qh->outfn : NULL,
-+		.next_queuenum = queuenum,
-+#endif
- 	};
- 
- 	/* If it's going away, ignore hook. */
-@@ -170,8 +209,19 @@ static int __nf_queue(struct sk_buff *sk
- 	}
- #endif
- 	afinfo->saveroute(skb, entry);
 +
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+	if (qih) {
-+		status = qih->outfn(entry, queuenum);
-+		goto imq_skip_queue;
-+	}
-+#endif
 +
- 	status = qh->outfn(entry, queuenum);
- 
-+#if defined(CONFIG_IMQ) || defined(CONFIG_IMQ_MODULE)
-+imq_skip_queue:
-+#endif
- 	rcu_read_unlock();
- 
- 	if (status < 0) {
---- /dev/null
-+++ b/net/netfilter/xt_IMQ.c
-@@ -0,0 +1,73 @@
-+/*
-+ * This target marks packets to be enqueued to an imq device
-+ */
-+#include <linux/module.h>
-+#include <linux/skbuff.h>
-+#include <linux/netfilter/x_tables.h>
-+#include <linux/netfilter/xt_IMQ.h>
-+#include <linux/imq.h>
 +
-+static unsigned int imq_target(struct sk_buff *pskb,
-+				const struct xt_target_param *par)
++
++
++
++
++
++
++
++
++
++
++
++
++
++
++static int __init imq_init_one(int index)
 +{
-+	const struct xt_imq_info *mr = par->targinfo;
++	struct net_device *dev;
++	int ret;
 +
-+	pskb->imq_flags = (mr->todev & IMQ_F_IFMASK) | IMQ_F_ENQUEUE;
++	dev = alloc_netdev(0, "imq%d", imq_setup);
++	if (!dev)
++		return -ENOMEM;
 +
-+	return XT_CONTINUE;
++	ret = dev_alloc_name(dev, dev->name);
++	if (ret < 0)
++		goto fail;
++
++	dev->rtnl_link_ops = &imq_link_ops;
++	ret = register_netdevice(dev);
++	if (ret < 0)
++		goto fail;
++
++	return 0;
++fail:
++	free_netdev(dev);
++	return ret;
 +}
 +
-+static bool imq_checkentry(const struct xt_tgchk_param *par)
++static int __init imq_init_devs(void)
 +{
-+	struct xt_imq_info *mr = par->targinfo;
++	int err, i;
 +
-+	if (mr->todev > IMQ_MAX_DEVS - 1) {
-+		printk(KERN_WARNING
-+		       "IMQ: invalid device specified, highest is %u\n",
-+		       IMQ_MAX_DEVS - 1);
-+		return 0;
++	if (numdevs < 1 || numdevs > IMQ_MAX_DEVS) {
++		printk(KERN_ERR "IMQ: numdevs has to be betweed 1 and %u\n",
++		       IMQ_MAX_DEVS);
++		return -EINVAL;
 +	}
 +
-+	return 1;
++	rtnl_lock();
++	err = __rtnl_link_register(&imq_link_ops);
++
++	for (i = 0; i < numdevs && !err; i++)
++		err = imq_init_one(i);
++
++	if (err) {
++		__rtnl_link_unregister(&imq_link_ops);
++		memset(imq_devs_cache, 0, sizeof(imq_devs_cache));
++	}
++	rtnl_unlock();
++
++	return err;
 +}
 +
-+static struct xt_target xt_imq_reg[] __read_mostly = {
-+	{
-+		.name           = "IMQ",
-+		.family		= AF_INET,
-+		.checkentry     = imq_checkentry,
-+		.target         = imq_target,
-+		.targetsize	= sizeof(struct xt_imq_info),
-+		.table		= "mangle",
-+		.me             = THIS_MODULE
-+	},
-+	{
-+		.name           = "IMQ",
-+		.family		= AF_INET6,
-+		.checkentry     = imq_checkentry,
-+		.target         = imq_target,
-+		.targetsize	= sizeof(struct xt_imq_info),
-+		.table		= "mangle",
-+		.me             = THIS_MODULE
-+	},
-+};
++static int __init imq_init_module(void)
++{
++	int err;
 +
-+static int __init imq_init(void)
++#if defined(CONFIG_IMQ_NUM_DEVS)
++	BUILD_BUG_ON(CONFIG_IMQ_NUM_DEVS > 16);
++	BUILD_BUG_ON(CONFIG_IMQ_NUM_DEVS < 2);
++	BUILD_BUG_ON(CONFIG_IMQ_NUM_DEVS - 1 > IMQ_F_IFMASK);
++#endif
++
++	err = imq_init_devs();
++	if (err) {
++		printk(KERN_ERR "IMQ: Error trying imq_init_devs(net)\n");
++		return err;
++	}
++
++	err = imq_init_hooks();
++	if (err) {
++		printk(KERN_ERR "IMQ: Error trying imq_init_hooks()\n");
++		rtnl_link_unregister(&imq_link_ops);
++		memset(imq_devs_cache, 0, sizeof(imq_devs_cache));
++		return err;
++	}
++
++	printk(KERN_INFO "IMQ driver loaded successfully.\n");
++
++	return 0;
++}
++
++static void __exit imq_cleanup_devs(void)
 +{
-+	return xt_register_targets(xt_imq_reg, ARRAY_SIZE(xt_imq_reg));
++	rtnl_link_unregister(&imq_link_ops);
++	memset(imq_devs_cache, 0, sizeof(imq_devs_cache));
 +}
 +
-+static void __exit imq_fini(void)
++static void __exit imq_exit_module(void)
 +{
-+	xt_unregister_targets(xt_imq_reg, ARRAY_SIZE(xt_imq_reg));
++	imq_unhook();
++	imq_cleanup_devs();
++	printk(KERN_INFO "IMQ driver unloaded successfully.\n");
 +}
 +
-+module_init(imq_init);
-+module_exit(imq_fini);
++module_init(imq_init_module);
++module_exit(imq_exit_module);
++
++
++
++module_param(numdevs, int, 0);
++module_param(hook_chains, charp, 0);
++module_param(hook_tables, charp, 0);
++
++MODULE_PARM_DESC(numdevs, "number of IMQ devices (how many imq* devices will be created)");
++MODULE_PARM_DESC(hook_chains, "netfilter chains in which to insert hooks to IMQ");
++MODULE_PARM_DESC(hook_tables, "netfilter tables after which to insert hooks to IMQ");
++
++
 +
 +MODULE_AUTHOR("http://www.linuximq.net");
-+MODULE_DESCRIPTION("Pseudo-driver for the intermediate queue device. See http://www.linuximq.net/ for more information.");
++MODULE_DESCRIPTION("Pseudo-driver for the intermediate queue device. See "
++			"http://www.linuximq.net/ for more information.");
 +MODULE_LICENSE("GPL");
-+MODULE_ALIAS("ipt_IMQ");
-+MODULE_ALIAS("ip6t_IMQ");
++MODULE_ALIAS_RTNL_LINK("imq");
 +
